#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Export FAQ from Database to Training Data
‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ ‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á training data
"""

import mysql.connector
import pandas as pd
import os
from datetime import datetime

# ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
DB_CONFIG = {
    'host': 'localhost',
    'port': 3306,
    'database': 'eng_chatbot',
    'user': 'root',
    'password': '',
    'charset': 'utf8mb4'
}

def normalize_intent(category):
    """
    ‡πÅ‡∏°‡∏õ category ‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á intent ‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    ‡∏•‡∏î‡∏à‡∏≤‡∏Å 57 categories ‡∏•‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 10 ‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å
    """
    # ‡πÅ‡∏°‡∏õ‡∏ó‡∏∏‡∏Å category ‡πÑ‡∏õ‡∏¢‡∏±‡∏á intent ‡∏´‡∏•‡∏±‡∏Å
    intent_mapping = {
        # ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤
        'program': 'program',
        'curriculum': 'program',
        'Curriculum': 'program',
        'Courses': 'program',
        'course': 'program',
        'Course Description': 'program',
        '‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡∏ä‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô': 'program',
        '‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£': 'program',
        '‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤': 'program',
        '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤': 'program',
        
        # ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£
        'admission': 'admission',
        'Admission': 'admission',
        '‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£': 'admission',
        '‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥': 'admission',
        
        # ‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
        'career': 'career',
        'Careers': 'career',
        '‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡πÅ‡∏•‡∏∞‡πÉ‡∏ö‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï': 'career',
        
        # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡∏≠‡∏°‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢
        'tuition': 'tuition',
        'fee': 'tuition',
        'Fees': 'tuition',
        '‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°': 'tuition',
        
        # ‡∏ó‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡∏Å‡∏π‡πâ‡∏¢‡∏∑‡∏°
        'loan': 'loan',
        'scholarship': 'loan',
        'Scholarship': 'loan',
        
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠
        'contact': 'contact',
        'location': 'contact',
        
        # ‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å
        'facilities': 'facilities',
        'Facilities': 'facilities',
        'facility': 'facilities',
        'library': 'facilities',
        'sports': 'facilities',
        
        # ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£
        'activities': 'activities',
        '‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°': 'activities',
        
        # ‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô
        'research': 'research',
        'Research': 'research',
        '‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏á‡∏≤‡∏ô': 'research',
        '‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢': 'research',
        
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        'information': 'general',
        'general': 'general',
        'General Info': 'general',
        'about': 'general',
        'history': 'general',
        'accreditation': 'general',
        '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ': 'general',
        'faq': 'general',
        'Faculty': 'general',
        'staff': 'general',
        'document': 'general',
        'cooperation': 'general',
        'partnership': 'general',
        'Co-op': 'general',
        
        # ‡∏Å‡∏≤‡∏£‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤
        'Graduation': 'graduation',
        '‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤': 'graduation',
        
        # ‡∏Å‡∏é‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö
        'Regulations': 'regulations',
        'Student Support': 'regulations',
    }
    
    # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ intent ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡∏õ‡πÅ‡∏•‡πâ‡∏ß ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ 'general'
    return intent_mapping.get(category, 'general')

def connect_db():
    """‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    try:
        conn = mysql.connector.connect(**DB_CONFIG)
        print("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        return conn
    except mysql.connector.Error as err:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {err}")
        return None

def fetch_faq_data(conn):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ ‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    query = """
        SELECT id, question, answer, category, keywords
        FROM faq
        ORDER BY category, id
    """
    
    try:
        df = pd.read_sql(query, conn)
        print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ: {len(df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        return df
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        return None

def generate_question_variations(question, category):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å
    """
    variations = [question]  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
    
    # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ category
    if category == 'program':
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£
        if '‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£' in question or '‡∏≠‡∏™.‡∏ö' in question or '‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°' in question:
            variations.extend([
                question + ' ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£',
                question + ' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏≠‡∏∞‡πÑ‡∏£',
                '‡∏ö‡∏≠‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö' + question,
            ])
        if '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏µ‡πà‡∏õ‡∏µ' in question or '‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤' in question:
            variations.extend([
                '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ô‡∏≤‡∏ô‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô',
                '‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏µ‡πà‡∏õ‡∏µ',
                '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏Å‡∏µ‡πà‡∏õ‡∏µ‡∏à‡∏ö',
                '‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô'
            ])
        if '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô' in question and '‡∏ß‡∏¥‡∏ä‡∏≤' in question:
            variations.extend([
                '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏≠‡∏∞‡πÑ‡∏£',
                '‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ß‡∏¥‡∏ä‡∏≤‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á',
                '‡∏°‡∏µ‡∏ß‡∏¥‡∏ä‡∏≤‡∏≠‡∏∞‡πÑ‡∏£',
            ])
            
    elif category == 'admission':
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£/‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥
        variations.extend([
            '‡∏™‡∏°‡∏±‡∏Ñ‡∏£',
            '‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°',
            '‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏¢‡∏±‡∏á‡πÑ‡∏á',
            '‡∏ß‡∏¥‡∏ò‡∏µ‡∏™‡∏°‡∏±‡∏Ñ‡∏£',
            '‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£',
            '‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£',
            'TCAS',
            '‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏á',
            '‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥',
            '‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£ ‡∏°‡∏ó‡∏£',
        ])
            
    elif category == 'tuition':
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡∏≠‡∏° - ‡πÄ‡∏û‡∏¥‡πà‡∏° variations ‡πÄ‡∏¢‡∏≠‡∏∞‡∏Ç‡∏∂‡πâ‡∏ô
        variations.extend([
            '‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡∏≠‡∏°',
            '‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡∏≠‡∏°‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà',
            '‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡∏≠‡∏°‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£',
            '‡πÄ‡∏ó‡∏≠‡∏°‡∏•‡∏∞‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà',
            '‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô',
            '‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢',
            '‡πÄ‡∏™‡∏µ‡∏¢‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà',
            '‡∏Ñ‡πà‡∏≤‡∏ò‡∏£‡∏£‡∏°‡πÄ‡∏ô‡∏µ‡∏¢‡∏°',
            '‡∏Ñ‡πà‡∏≤‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô',
            '‡∏Ñ‡πà‡∏≤‡∏ö‡∏≥‡∏£‡∏∏‡∏á',
            '‡∏£‡∏≤‡∏Ñ‡∏≤',
            '‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô',
            '‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡πÄ‡∏ó‡∏≠‡∏°',
            '‡∏à‡πà‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡πÄ‡∏ó‡∏≠‡∏°',
            '‡πÅ‡∏û‡∏á‡πÑ‡∏´‡∏°',
            '‡∏ñ‡∏π‡∏Å‡πÑ‡∏´‡∏°',
            '‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà',
            '‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£',
            '‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà',
            '‡πÄ‡∏ó‡∏≠‡∏°‡∏•‡∏∞‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏£',
            '‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà',
        ])
        
    elif category == 'loan':
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏π‡πâ‡∏¢‡∏∑‡∏°‡πÅ‡∏•‡∏∞‡∏ó‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ - ‡πÄ‡∏û‡∏¥‡πà‡∏° variations ‡πÄ‡∏¢‡∏≠‡∏∞‡∏Ç‡∏∂‡πâ‡∏ô
        variations.extend([
            '‡∏Å‡∏π‡πâ‡πÄ‡∏á‡∏¥‡∏ô ‡∏Å‡∏¢‡∏®',
            '‡∏Å‡∏π‡πâ ‡∏Å‡∏¢‡∏®',
            '‡∏Å‡∏¢‡∏® ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£',
            '‡∏Ç‡∏≠‡∏Å‡∏π‡πâ‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°',
            '‡∏Å‡∏π‡πâ‡∏¢‡∏∑‡∏°‡πÄ‡∏á‡∏¥‡∏ô',
            '‡∏ó‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤',
            '‡∏Ç‡∏≠‡∏ó‡∏∏‡∏ô',
            '‡∏°‡∏µ‡∏ó‡∏∏‡∏ô‡πÑ‡∏´‡∏°',
            '‡∏Å‡∏¢‡∏®. ‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°',
            '‡∏Å‡∏π‡πâ‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏ô',
        ])
        
    elif category == 'career':
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏≠‡∏≤‡∏ä‡∏µ‡∏û
        variations.extend([
            '‡∏à‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏∞‡πÑ‡∏£',
            '‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á',
            '‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏´‡∏•‡∏±‡∏á‡∏à‡∏ö',
            '‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡πÑ‡∏´‡∏ô',
            '‡∏°‡∏µ‡∏á‡∏≤‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á'
        ])
        
    elif category == 'contact':
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠
        variations.extend([
            '‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏¢‡∏±‡∏á‡πÑ‡∏á',
            '‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£',
            '‡∏≠‡∏µ‡πÄ‡∏°‡∏•',
            '‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà',
            '‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤'
        ])
        
    elif category == 'facilities':
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å
        variations.extend([
            '‡∏°‡∏µ‡∏´‡πâ‡∏≠‡∏á‡πÅ‡∏•‡πá‡∏ö‡πÑ‡∏´‡∏°',
            '‡∏°‡∏µ‡∏´‡πâ‡∏≠‡∏á‡∏™‡∏°‡∏∏‡∏î‡πÑ‡∏´‡∏°',
            '‡∏™‡∏ô‡∏≤‡∏°‡∏Å‡∏µ‡∏¨‡∏≤',
            '‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô'
        ])
        
    elif category == 'general':
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        if '‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå' in question or 'staff' in question.lower():
            variations.extend([
                '‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏™‡∏≤‡∏Ç‡∏≤',
                '‡∏Ñ‡∏ì‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå',
                '‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏ú‡∏π‡πâ‡∏™‡∏≠‡∏ô',
            ])
    
    return variations

def create_training_data(df):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á training data ‡∏à‡∏≤‡∏Å FAQ"""
    training_data = []
    
    for idx, row in df.iterrows():
        question = row['question']
        category = row['category']
        
        # ‡πÅ‡∏õ‡∏•‡∏á category ‡πÄ‡∏õ‡πá‡∏ô intent ‡∏´‡∏•‡∏±‡∏Å
        normalized_intent = normalize_intent(category)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á variations ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
        variations = generate_question_variations(question, normalized_intent)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏ï‡πà‡∏•‡∏∞ variation ‡πÄ‡∏õ‡πá‡∏ô training example
        for var in variations:
            training_data.append({
                'question': var,
                'intent': normalized_intent,  # ‡πÉ‡∏ä‡πâ normalized intent
                'original_faq_id': row['id'],
                'original_category': category  # ‡πÄ‡∏Å‡πá‡∏ö category ‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
            })
    
    return pd.DataFrame(training_data)

def save_training_data(df, output_path):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å training data"""
    try:
        df.to_csv(output_path, index=False, encoding='utf-8-sig')
        print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å training data: {output_path}")
        print(f"   ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô: {len(df)} examples")
        return True
    except Exception as e:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå: {e}")
        return False

def main():
    print("=" * 70)
    print("EXPORT FAQ FROM DATABASE TO TRAINING DATA")
    print("=" * 70)
    print()
    
    # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    conn = connect_db()
    if not conn:
        return
    
    try:
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ
        print("\n[1/4] ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ ‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        faq_df = fetch_faq_data(conn)
        
        if faq_df is None or len(faq_df) == 0:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
            return
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• FAQ
        print("\nFAQ by Category:")
        print(faq_df.groupby('category').size())
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á training data
        print("\n[2/4] ‡∏™‡∏£‡πâ‡∏≤‡∏á training data ‡πÅ‡∏•‡∏∞ variations...")
        training_df = create_training_data(faq_df)
        
        print(f"\nTraining data created:")
        print(f"  - Original FAQ: {len(faq_df)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        print(f"  - Training examples: {len(training_df)} examples")
        print(f"\nExamples by Intent:")
        print(training_df.groupby('intent').size())
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å training data
        print("\n[3/4] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å training data...")
        output_dir = os.path.join(os.path.dirname(__file__), '..', 'data')
        output_path = os.path.join(output_dir, 'faq_training_data.csv')
        
        if save_training_data(training_df, output_path):
            # ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤
            old_file = os.path.join(output_dir, 'training_data.csv')
            if os.path.exists(old_file):
                backup_file = os.path.join(output_dir, f'training_data_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv')
                os.rename(old_file, backup_file)
                print(f"üì¶ ‡∏™‡∏≥‡∏£‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤: {backup_file}")
            
            # ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå training_data.csv
            training_df.to_csv(old_file, index=False, encoding='utf-8-sig')
            print(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï training_data.csv")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
        print("\n[4/4] ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Training Data:")
        print("-" * 70)
        for intent in training_df['intent'].unique()[:3]:
            print(f"\nIntent: {intent}")
            examples = training_df[training_df['intent'] == intent]['question'].head(3).tolist()
            for i, ex in enumerate(examples, 1):
                print(f"  {i}. {ex}")
        
        print("\n" + "=" * 70)
        print("‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")
        print("=" * 70)
        print("\nNext steps:")
        print("1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå: ai/data/faq_training_data.csv")
        print("2. Train ‡πÇ‡∏°‡πÄ‡∏î‡∏•: python ai/scripts/train_model.py")
        print("3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: python ai/scripts/test_model.py")
        
    finally:
        conn.close()
        print("\nüîå ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")

if __name__ == '__main__':
    main()
