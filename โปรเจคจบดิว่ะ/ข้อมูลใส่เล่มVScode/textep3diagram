บทที่ 3
ขั้นตอนและวิธีการดำเนินงาน

3.1 ภาพรวมกระบวนการพัฒนา
	การพัฒนาระบบ Chatbot อัจฉริยะสำหรับคณะวิศวกรรมศาสตร์ มหาวิทยาลัยเทคโนโลยีราชมงคล  พระนคร ได้ดำเนินการตามกระบวนการพัฒนาซอฟต์แวร์แบบ Incremental Development โดยแบ่งการพัฒนาออกเป็น 5 ขั้นตอนหลัก ดังนี้:
ขั้นตอนที่ 1: วิเคราะห์ความต้องการและออกแบบระบบ
ขั้นตอนที่ 2: จัดเตรียมฐานข้อมูล
ขั้นตอนที่ 3: พัฒนาระบบ Backend และ Frontend
ขั้นตอนที่ 4: พัฒนาระบบ AI/ML สำหรับการจำแนกความตั้งใจ
ขั้นตอนที่ 5: ทดสอบและปรับปรุงระบบ
แต่ละขั้นตอนได้รับการวางแผนและดำเนินการอย่างเป็นระบบ โดยมีการทบทวนและปรับปรุงอย่างต่อเนื่องเพื่อให้ได้ระบบที่มีประสิทธิภาพสูงสุด

3.2 ขั้นตอนที่ 1: วิเคราะห์ความต้องการและออกแบบระบบ
	3.2.1 การวิเคราะห์ความต้องการ
		3.2.1.1 การรวบรวมความต้องการ (Requirements Gathering)
		ทีมผู้พัฒนาได้ดำเนินการรวบรวมความต้องการจากกลุ่มผู้ใช้งาน 3 กลุ่มหลัก:
		1. นักศึกษาปัจจุบันและผู้สนใจสมัครเรียน
		- ต้องการสอบถามข้อมูลการรับสมัคร (TCAS, รอบต่างๆ, คุณสมบัติ, เอกสาร)
  		- ต้องการทราบข้อมูลค่าเทอม การผ่อนชำระ
  		- ต้องการสอบถามข้อมูลทุนการศึกษา (กยศ./กรอ.)
		- ต้องการข้อมูลสาขาวิชา หลักสูตร และความแตกต่าง
		- ต้องการค้นหาอาจารย์ที่ปรึกษา อาจารย์ผู้สอน
		- ต้องการบริการตอบคำถามตลอด 24 ชั่วโมง

		2. เจ้าหน้าที่และอาจารย์
		- ต้องการลดภาระงานตอบคำถามซ้ำๆ
		- ต้องการระบบจัดการ FAQ ที่ใช้งานง่าย
		- ต้องการดูประวัติการสนทนาเพื่อวิเคราะห์พฤติกรรม
		- ต้องการระบบที่ปลอดภัยและควบคุมได้
		3. ผู้ปกครองและบุคคลทั่วไป
		- ต้องการข้อมูลเบื้องต้นเกี่ยวกับคณะและสาขาวิชา
		- ต้องการช่องทางติดต่อคณะ
		- ต้องการข้อมูลที่เข้าใจง่าย ไม่ซับซ้อน
		3.2.1.2 การกำหนดขอบเขตระบบ (System Scope)
		จากการวิเคราะห์ความต้องการ ได้กำหนดขอบเขตของระบบดังนี้:
		1. ขอบเขตที่รวมในระบบ
		- ระบบตอบคำถามอัตโนมัติด้วย AI/ML
		- ฐานข้อมูลบุคลากร 118 คน จาก 10 สาขาวิชา
		- ฐานข้อมูล FAQ ครอบคลุมหลายหมวดหมู่ (มีทั้งหมด 554 รายการ)
		- ระบบจัดการข้อมูล (Admin Dashboard)
		- การบันทึกประวัติการสนทนา
		- ระบบความปลอดภัย (CORS, Rate Limiting, Input Validation)
		- Interface แบบ Responsive รองรับทุกอุปกรณ์
		2. ขอบเขตที่ไม่รวมในระบบ
		- การบูรณาการกับระบบทะเบียนนักศึกษา
		- การประมวลผลเสียง (Voice Recognition)
		- ระบบสมัครเรียนออนไลน์
		- การวิเคราะห์ข้อมูลเชิงลึก (Advanced Analytics)
		- รองรับภาษาต่างประเทศ



	3.2.2 การออกแบบสถาปัตยกรรมระบบ
		3.2.2.1 สถาปัตยกรรมแบบ 3-Tier Architecture ระบบได้รับการออกแบบด้วยสถาปัตยกรรมแบบ 3 ชั้น (3-Tier Architecture) เพื่อแยกความรับผิดชอบของแต่ละส่วนให้ชัดเจน ประกอบด้วย:

┌─────────────────────────────────────────────────────────┐
│        Presentation Layer (Frontend)                    │
│  - HTML5, CSS3, JavaScript (ES6+)                       │
│  - Responsive Design (Mobile-First)                     │
│  - AJAX สำหรับการสื่อสารแบบ Asynchronous               │
│  - Dark Mode Support                                    │
└────────────────────┬────────────────────────────────────┘
                     │ HTTP/HTTPS (JSON)
┌────────────────────▼────────────────────────────────────┐
│        Application Layer (Backend)                      │
│  - PHP 8.0+ (Business Logic)                            │
│  - REST API Architecture                                │
│  - NLP Processing (Keyword Matching, Synonym Expansion) │
│  - AI/ML Integration (Python Flask API)                 │
│  - Security Middleware (CORS, Rate Limiting)            │
└────────────────────┬────────────────────────────────────┘
                     │ PDO (MySQL)
┌────────────────────▼────────────────────────────────────┐
│        Data Layer (Database)                            │
│  - MySQL 8.0+ / MariaDB                                 │
│  - ตาราง: staff, faqs, news, chat_logs, admin_users    │
│  - ACID Compliance                                      │
│  - Index Optimization (BTREE, FULLTEXT)                 │
└─────────────────────────────────────────────────────────┘

		3.2.2.2 การออกแบบฐานข้อมูล (Database Design) ออกแบบฐานข้อมูลตามหลักการ Normalization ถึง Third Normal Form (3NF) เพื่อลดความซ้ำซ้อนของข้อมูล
		ตารางหลัก
		1. ตาราง staff - จัดเก็บข้อมูลบุคลากร 118 คน จาก 10 สาขาวิชา ประกอบด้วยข้อมูลชื่อ-นามสกุล ตำแหน่งทางวิชาการ สาขาที่สังกัด ข้อมูลติดต่อ และความเชี่ยวชาญ
		2. ตาราง faqs - จัดเก็บคำถาม-คำตอบทั้งหมด 554 รายการ ครอบคลุม 12 หมวดหมู่ (admission, tuition, loan, scholarship, program, career, facilities, general, contact, research, activities, graduation, regulations) พร้อม FULLTEXT Index สำหรับการค้นหาข้อมูลภาษาไทย
		3. ตาราง departments - จัดเก็บข้อมูล 10 สาขาวิชาในคณะวิศวกรรมศาสตร์ ทำหน้าที่เป็น Master Data สำหรับการอ้างอิง

		4. ตาราง chat_logs - บันทึกประวัติการสนทนาทั้งหมด พร้อมข้อมูล intent, confidence, response_time และ user_feedback เพื่อนำไปวิเคราะห์และปรับปรุงระบบ
		5. ตาราง admin_users - จัดเก็บข้อมูลผู้ดูแลระบบพร้อมรหัสผ่านที่เข้ารหัสด้วยอัลกอริทึมที่ปลอดภัย
		3.2.2.3 Entity-Relationship Diagram (ERD) และความสัมพันธ์ระหว่างตาราง
แผนภาพความสัมพันธ์ระหว่างตาราง (ER-Diagram)

┌──────────────────────┐
│    departments       │  ◄─── Master Table (ข้อมูลอ้างอิง)
│  - id (PK)           │
│  - name_th           │
│  - code (UNIQUE)     │
│  (10 สาขา)           │
└──────────┬───────────┘
           │ 1
           │ has_many (มีหลายคน)
           │
           │ N
┌──────────▼───────────┐         ┌──────────────────────┐
│      staff           │         │     admin_users      │
│  - id (PK)           │         │  - id (PK)           │
│  - department (FK)   │         │  - username (UNIQUE) │
│  - name_th           │         │  (ผู้ดูแลระบบ)        │
│  - position          │         └──────────────────────┘
│  (118 คน)            │
└──────────┬───────────┘
           │ 1
           │ belongs_to (สังกัดสาขา)
           │
           │ N
┌──────────▼───────────┐         ┌──────────────────────┐
│      faqs            │         │    chat_logs         │
│  - id (PK)           │         │  - id (PK)           │
│  - question          │         │  - user_message      │
│  - answer            │         │  - bot_response      │
│  - category          │         │  - intent            │
│  - department (FK)   │         │  - confidence        │
│  - keywords          │         │  - session_id        │
│  (554 รายการ)         │         │  (บันทึกทุกการสนทนา)  │
└──────────────────────┘         └──────────────────────┘
		คำอธิบายความสัมพันธ์
		1. departments → staff (One-to-Many)
		- หนึ่งสาขาวิชาสามารถมีบุคลากรหลายคน
		- บุคลากรแต่ละคนต้องสังกัดสาขาวิชาเพียงหนึ่งสาขา
		- ใช้ฟิลด์ `department` ใน staff table เป็น Foreign Key อ้างอิงไปยัง `code` ใน departments table


		2. departments → faqs (One-to-Many)
		- หนึ่งสาขาวิชาสามารถมี FAQ เฉพาะสาขาหลายรายการ
		- FAQ บางรายการอาจไม่เกี่ยวข้องกับสาขาใดเฉพาะ (department = NULL สำหรับ FAQ ทั่วไป)
		- ใช้ฟิลด์ `department` ใน faqs table เป็น Foreign Key (ถ้ามีค่า)
		3. faqs และ chat_logs (Independent)
		- ทั้งสองตารางไม่มีความสัมพันธ์โดยตรง (No Foreign Key)
		- chat_logs บันทึก intent ที่ได้จากการจำแนกของ AI ซึ่งไม่ได้อ้างอิงไปยัง faq_id โดยตรง
		- ความสัมพันธ์เป็นแบบ Logical มากกว่า Physical (ผ่านการเปรียบเทียบ intent และ category)
		4. admin_users (Independent)
		- ตารางนี้เป็นอิสระ ไม่มีความสัมพันธ์กับตารางอื่น
		- ใช้สำหรับการ Authentication และ Authorization เท่านั้น
		หลักการออกแบบ
		- Normalization ออกแบบตามหลัก Third Normal Form (3NF) เพื่อลดความซ้ำซ้อน
		- Referential Integrity ใช้ Foreign Key Constraints เพื่อรักษาความสมบูรณ์ของข้อมูล
		- Index Optimization กำหนด Index บนคอลัมน์ที่ใช้ค้นหาบ่อย เช่น department, category, intent
		- Data Type Selection เลือก Data Type ที่เหมาะสม เช่น TEXT สำหรับข้อความยาว, VARCHAR สำหรับข้อความสั้น, DECIMAL สำหรับตัวเลขทศนิยม
	3.2.3 การออกแบบระบบ AI/ML
		3.2.3.1 การเลือกวิธีการ (Hybrid Approach)
		ระบบใช้แนวทาง Hybrid ที่ผสมผสานระหว่าง:
		1. Rule-based System - สำหรับคำถามที่ตรงกับ FAQ
		- Keyword Matching
		- Synonym Expansion
		- Fuzzy Matching
		- Relevance Scoring
		2. AI/ML System - สำหรับการจำแนกความตั้งใจ (Intent Classification)
		- TF-IDF (Term Frequency-Inverse Document Frequency)
		- Logistic Regression
		- Confidence Scoring
		3.2.3.2 Flow Chart: กระบวนการทำงานแบบ Hybrid Approach

แผนภาพกระบวนการ (Process Flow Diagram)

┌───────────────────────────────────────────────────┐
│      ผู้ใช้ส่งคำถาม (User Input)                         │
│   ตัวอย่าง: "สาขาวิศวคอมเรียนอะไร"                │
└──────────────────────┬───────────────────────────┘
                        │
                        ▼
┌───────────────────────────────────────────────────┐
│    ขั้นตอนที่ 1: Text Preprocessing                       │
│  - Tokenization (ตัดคำด้วย pythainlp)               │
│  - Lowercasing (แปลงเป็นตัวพิมพ์เล็ก)                   │
│  - Remove Stopwords (ลบคำเชื่อมที่ไม่สำคัญ)         │
│  - Normalization (เช่น วิศวฯ → วิศวกรรม)       │
│   ผลลัพธ์: ["สาขา", "วิศวกรรม",                  │
│             "คอมพิวเตอร์", "เรียน"]               │
└──────────────────────┬───────────────────────────┘
                        │
                        ▼
┌───────────────────────────────────────────────────┐
│  ขั้นตอนที่ 2: Intent Classification (AI/ML)         │
│  - TF-IDF Vectorization                               │
│  - Logistic Regression Model                          │
│  - คำนวณ Confidence Score                            │
│   ผลลัพธ์: Category = "program"                     │
│            Confidence = 0.94 (94%)                    │
└──────────────────────┬───────────────────────────┘
                        │
                        ▼
┌───────────────────────────────────────────────────┐
│  ขั้นตอนที่ 3: Decision Making                          │
│  ┌─────────────────────────────────────────────┐  │
│  │ Confidence ≥ 0.80 (80%)?                        │  │
│  └────────────┬────────────────────────────────┘  │
│              │                                        │
│      ใช่ ┌────▼────┐ ไม่ใช่                         │
│          │         │                                │
│          ▼         ▼                                │
│  ┌───────────────────────────────────────────┐  │
│  │ ค้นหา FAQ จาก Database              │  │
│  │ - ใช้ category จาก AI               │  │
│  │ - Keyword Matching                   │  │
│  │ - FULLTEXT Search                    │  │
│  │ - คำนวณ Relevance Score            │  │
│  └────────────┬─────────────────────────────┘  │
└──────────────│─────────────────────────────────────┘
                │
                ▼
┌───────────────────────────────────────────────────┐
│  ขั้นตอนที่ 4: Response Generation                      │
│  - สร้างคำตอบจาก FAQ ที่พบ                          │
│  - บันทึกเข้า chat_logs                               │
│  - เพิ่ม view_count ใน faqs table                   │
└──────────────────────┬───────────────────────────┘
                        │
                        ▼
┌───────────────────────────────────────────────────┐
│      แสดงคำตอบให้ผู้ใช้ (Output)                      │
│   ตัวอย่าง: "สาขาวิศวคอมพิวเตอร์เรียน           │
│             เกี่ยวกับ..."                         │
└───────────────────────────────────────────────────┘
```
		คำอธิบายแต่ละขั้นตอน
		ขั้นตอนที่ 1: Text Preprocessing
		- เป็นขั้นตอนแรกที่ทำการประมวลผลข้อความเบื้องต้น (Raw Text) ให้อยู่ในรูปแบบที่เหมาะสำหรับการประมวลผลด้วย AI
		- รวมถึงการตัดคำ (Tokenization), ลบ Stopwords, และการ Normalize ข้อความ
		- สำหรับภาษาไทย ใช้ pythainlp library ซึ่งเป็น State-of-the-art สำหรับ NLP ภาษาไทย
		ขั้นตอนที่ 2: Intent Classification (AI/ML)
		- ใช้เทคนิค TF-IDF (Term Frequency-Inverse Document Frequency) เพื่อแปลงข้อความเป็นเวกเตอร์ (Feature Vector)
- ใช้โมเดล Logistic Regression ทำการจำแนกหมวดหมู่ (Multi-class Classification)
- คำนวณ Confidence Score เพื่อวัดระดับความมั่นใจของการจำแนก
- ผลลัพธ์คือ Category (เช่น program, admission, tuition) และค่า Confidence (0.00-1.00)

ขั้นตอนที่ 3: Decision Making
- เกณฑ์การตัดสินใจ: ตรวจสอบว่า Confidence Score ≥ 0.80 (80%) หรือไม่
- ถ้า Confidence ≥ 0.80:
  - ระบบมั่นใจในการจำแนก → ใช้ AI/ML Result
  - เข้าสู่ขั้นตอน Rule-based Search
  - ค้นหา FAQ จาก Database โดยใช้ category ที่ได้จาก AI
- ถ้า Confidence < 0.80:
  - ระบบไม่มั่นใจ → ไม่ออกคำตอบ
  - แสดงข้อความขอโทษและแนะนำให้ติดต่อเจ้าหน้าที่

ขั้นตอนที่ 4: Response Generation
- ดึงข้อมูลคำตอบจาก FAQ ที่ค้นพบ
- บันทึกประวัติการสนทนาเข้า chat_logs table
- เพิ่มสถิติ view_count ของ FAQ นั้นๆ
- ส่งคำตอบพร้อม Metadata (เช่น confidence, category) กลับไปยัง Frontend

จุดเด่นของ Hybrid Approach:
1. ความแม่นยำสูง: AI/ML ให้ความแม่นยำสูง (87.3%) แม้จะมี Training Data จำกัด
2. ความรวดเร็ว: Rule-based Search ให้ผลลัพธ์รวดเร็ว (เฉลี่ย 267ms)
3. ความยืดหยุ่น: สามารถขยายระบบได้โดยไม่ต้องพึ่งพา Deep Learning Model
4. ความปลอดภัย: ใช้ Confidence Threshold เป็นตัวกรองป้องกันคำตอบที่ผิดพลาด

---

## 3.3 ขั้นตอนที่ 2: จัดเตรียมฐานข้อมูล

### 3.3.1 การรวบรวมข้อมูลบุคลากร

3.3.1.1 แหล่งข้อมูล

รวบรวมข้อมูลบุคลากรจากเว็บไซต์อย่างเป็นทางการของแต่ละสาขาวิชา ทั้งหมด 10 สาขาในคณะวิศวกรรมศาสตร์ รวมทั้งสิ้น 118 คน

3.3.1.2 ข้อมูลที่เก็บรวบรวม

สำหรับบุคลากรแต่ละคน เก็บข้อมูลดังนี้:
- ชื่อ-นามสกุล (ภาษาไทยและอังกฤษ)
- ตำแหน่งทางวิชาการ (อาจารย์, ผศ., รศ., ศ.)
- สาขาวิชาที่สังกัด
- อีเมลติดต่อ
- เบอร์โทรศัพท์
- ความเชี่ยวชาญ/สาขาที่สอน

3.3.1.3 กระบวนการนำเข้าข้อมูล

1. จัดเตรียมไฟล์ CSV ตามรูปแบบที่กำหนด
2. ตรวจสอบความถูกต้องของข้อมูล (Data Validation)
3. Import เข้าฐานข้อมูลผ่าน SQL Script
4. ตรวจสอบความสมบูรณ์ของข้อมูลที่นำเข้า

### 3.3.2 การรวบรวมข้อมูล FAQ

3.3.2.1 การวางแผนเก็บข้อมูล

จัดทำแผนการเก็บข้อมูล FAQ โดยแบ่งออกเป็น 12 หมวดหมู่หลัก:

| หมวดหมู่ | จำนวนเป้าหมาย | แหล่งข้อมูล |
|---------|----------------|------------|
| 1. การรับสมัคร (Admission) | 50 รายการ | https://reg.rmutp.ac.th/admissions/ |
| 2. ค่าเทอม (Tuition) | 30 รายการ | https://reg.rmutp.ac.th/tuition/ |
| 3. ทุนการศึกษา (Scholarship) | 50 รายการ | https://studentloan.rmutp.ac.th/ |
| 4. สาขาวิชา/หลักสูตร (Program) | 100 รายการ | เว็บไซต์แต่ละสาขา (10 สาขา) |
| 5. สิ่งอำนวยความสะดวก (Facilities) | 40 รายการ | เว็บห้องสมุด, ห้องกีฬา, ฯลฯ |
| 6. ข้อมูลทั่วไป (General) | 50 รายการ | https://eng.rmutp.ac.th/ |
| 7-12. อื่นๆ (Career, Contact, Research, etc.) | 100 รายการ | แหล่งข้อมูลต่างๆ |
| รวม (ผลลัพธ์จริง) | 554 รายการ | |

3.3.2.2 โครงสร้างข้อมูล FAQ

ข้อมูล FAQ จัดเก็บในรูปแบบ JSON ประกอบด้วยฟิลด์สำคัญ: question (คำถาม), answer (คำตอบ), category (หมวดหมู่), department (สาขาที่เกี่ยวข้อง), keywords (คำสำคัญสำหรับค้นหา), และ source_url (แหล่งอ้างอิง) โครงสร้างนี้มีความยืดหยุ่นในการจัดการและสามารถ Import/Export ข้อมูลได้ง่ายผ่าน Admin Dashboard

3.3.2.3 กระบวนการสร้าง Training Data

เพื่อเพิ่มประสิทธิภาพของโมเดล AI ได้สร้าง Question Variations อัตโนมัติ โดยจาก FAQ 554 รายการ สร้าง Training Data ได้ทั้งหมด 3,212 รายการ ซึ่งช่วยเพิ่มความหลากหลายของคำถามและปรับปรุงความแม่นยำในการจำแนก Intent

3.3.2.4 การจัดหมวดหมู่ (Categories)

กำหนดหมวดหมู่สำหรับการจำแนกความตั้งใจ (Intent) 12 หมวดหมู่:

1. program - คำถามเกี่ยวกับหลักสูตร/สาขาวิชา
2. admission - คำถามเกี่ยวกับการรับสมัคร
3. tuition - คำถามเกี่ยวกับค่าเทอม
4. loan - คำถามเกี่ยวกับกู้ยืมเงิน (กยศ./กรอ.)
5. scholarship - คำถามเกี่ยวกับทุนการศึกษา
6. career - คำถามเกี่ยวกับอาชีพหลังจบ
7. facilities - คำถามเกี่ยวกับสิ่งอำนวยความสะดวก
8. general - คำถามข้อมูลทั่วไป
9. contact - คำถามเกี่ยวกับการติดต่อ
10. research - คำถามเกี่ยวกับงานวิจัย
11. activities - คำถามเกี่ยวกับกิจกรรม
12. graduation/regulations - คำถามเกี่ยวกับการสำเร็จการศึกษา/ระเบียบ

---

## 3.4 ขั้นตอนที่ 3: พัฒนาระบบ Backend และ Frontend

### 3.4.1 การพัฒนา Backend

3.4.1.1 เทคโนโลยีที่ใช้

- ภาษา: PHP 8.0+
- Database Driver: PDO (PHP Data Objects)
- Architecture: REST API
- Web Server: Apache 2.4+ (XAMPP)

3.4.1.2 สถาปัตยกรรมไฟล์ Backend

ระบบ Backend ถูกออกแบบตามหลัก Separation of Concerns โดยแยกหน้าที่ความรับผิดชอบออกเป็นไฟล์ต่างหาก ดังนี้:

1. chatbot.php - จุดเข้าหลัก (Main API Endpoint)
   - รับคำถามจากผู้ใช้และส่งคำตอบกลับ
   - ประมวลผลคำถามผ่าน AI/ML และ Rule-based System
   - บันทึกประวัติการสนทนา

2. admin_api.php - API สำหรับ Admin Dashboard
   - จัดการข้อมูล FAQ (CRUD Operations)
   - จัดการข้อมูลบุคลากร
   - ดึงรายงานสถิติและ Chat Logs

3. admin_login.php - ระบบยืนยันตัวตน (Authentication)
   - ตรวจสอบ Username และ Password
   - สร้าง Session Token สำหรับการเข้าใช้ระบบ
   - บันทึกเวลาเข้าใช้ครั้งล่าสุด

4. db.php - การเชื่อมต่อฐานข้อมูล (Database Connection)
   - จัดการการเชื่อมต่อ MySQL Database ด้วย PDO
   - ตั้งค่า Configuration (โฮสต์, Username, Password, Database Name)
   - จัดการ Error Handling สำหรับกรณีเชื่อมต่อล้มเหลว

5. security.php - มาตรการความปลอดภัย (Security Middleware)
   - CORS (Cross-Origin Resource Sharing) Configuration
   - Rate Limiting (จำกัดจำนวน Request ต่อนาที)
   - Input Validation และ Sanitization
   - SQL Injection Prevention

หลักการออกแบบ: การแยกไฟล์ตามหน้าที่ทำให้ง่ายต่อการดูแลและพัฒนาระบบ สอดคล้องกับหลัก Single Responsibility Principle ใน Software Engineering

3.4.1.3 การออกแบบ REST API

API Endpoint หลัก: `/backend/chatbot.php`

โครงสร้าง Request และ Response:

ระบบรับ HTTP POST Request จากฝั่ง Frontend ในรูปแบบ JSON ประกอบด้วย:
- message: ข้อความจากผู้ใช้ เช่น "ค่าเทอมสาขาคอมเท่าไหร่"
- session_id: รหัสประจำเซสชัน สำหรับติดตามการสนทนาของผู้ใช้แต่ละคน

และส่ง Response กลับในรูปแบบ JSON ประกอบด้วย:
- status: สถานะการทำงาน (success/error)
- answer: คำตอบที่ระบบหาได้จากฐานข้อมูล
- confidence: ค่าความมั่นใจของ AI (0.00-1.00)
- category: หมวดหมู่ที่ AI จำแนกได้ (program, admission, tuition, etc.)
- department: สาขาวิชาที่เกี่ยวข้อง (ถ้ามี)
- sources: รหัส FAQ ที่ใช้อ้างอิง
- response_time: เวลาที่ใช้ในการประมวลผล (milliseconds)

ข้อดีของการใช้ REST API:
- Standard Protocol: ใช้มาตรฐาน HTTP ที่เป็นที่ยอมรับทั่วโลก
- Stateless: แต่ละ Request เป็นอิสระ ไม่ขึ้นกับ Request ก่อนหน้า
- Flexible: สามารถเชื่อมต่อกับ Frontend หลากหลายรูปแบบ (Web, Mobile App)
- Scalable: ง่ายต่อการขยายระบบในอนาคต

3.4.1.4 ขั้นตอนการประมวลผล (Processing Pipeline)

ระบบ Backend ประมวลผลคำถามจากผู้ใช้ผ่าน 5 ขั้นตอนหลัก:

ขั้นตอนที่ 1: Input Validation & Sanitization
- รับข้อความจาก HTTP POST Request
- ตรวจสอบความถูกต้องของข้อมูลนำเข้า (ไม่เป็นค่าว่าง, ความยาวไม่เกิน 500 ตัวอักษร)
- ทำความสะอาดข้อมูล (Sanitization) เพื่อป้องกัน XSS Attack และ SQL Injection
- แปลง Special Characters เป็น HTML Entities (htmlspecialchars)

ขั้นตอนที่ 2: Intent Classification ด้วย AI/ML Model
- ส่งคำถามไปยัง Python Flask API Server (Port 5000)
- รอรับผลการจำแนกความตั้งใจ (Intent) และค่าความมั่นใจ (Confidence Score)
- กำหนด Timeout ที่ 2 วินาที หากเกินเวลาจะใช้ Rule-based System แทน

ขั้นตอนที่ 3: FAQ Search & Retrieval
- กรณี Confidence ≥ 0.80: ใช้ category จาก AI เป็นตัวกรองหลัก แล้วค้นหาด้วย Keyword Matching และ FULLTEXT Search
- กรณี Confidence < 0.80: ไม่นำ AI result ไปใช้ แต่แสดงข้อความขอโทษและแนะนำให้ติดต่อเจ้าหน้าที่
- คำนวณ Relevance Score สำหรับแต่ละ FAQ ที่พบ แล้วเลือก FAQ ที่มี Score สูงสุด

ขั้นตอนที่ 4: Logging & Analytics
- บันทึกข้อมูลการสนทนาเข้า chat_logs table ประกอบด้วย:
  - คำถาม, คำตอบ, intent, confidence, response_time, session_id, ip_address
- เพิ่มค่า view_count ในตาราง faqs สำหรับ FAQ ที่ถูกเรียกใช้
- บันทึก Timestamp สำหรับการวิเคราะห์ Usage Pattern

ขั้นตอนที่ 5: Response Formatting & Return
- จัดรูปแบบข้อมูลเป็น JSON Structure ที่กำหนด
- ตั้งค่า HTTP Headers (Content-Type: application/json, CORS Headers)
- ส่ง HTTP Response Code ที่เหมาะสม (200 OK, 400 Bad Request, 500 Server Error)
- คำนวณและแนบ response_time ไปด้วย

3.4.1.5 มาตรการความปลอดภัย (Security Measures)

ระบบได้นำมาตรการความปลอดภัยหลายระดับมาใช้เพื่อปกป้องระบบและข้อมูลผู้ใช้:

1. CORS (Cross-Origin Resource Sharing) Policy
- กำหนดว่า Request จาก Domain ใดบ้างที่สามารถเรียกใช้ API ได้
- จำกัด HTTP Methods ที่อนุญาต (POST, GET, OPTIONS เท่านั้น)
- กำหนด Headers ที่อนุญาตให้ส่งมาได้ (Content-Type, Authorization)
- วัตถุประสงค์: ป้องกันการเข้าถึง API จาก Malicious Websites

2. Rate Limiting
- จำกัดจำนวน Request สูงสุดที่ 10 ครั้ง ต่อนาที ต่อ IP Address หนึ่งๆ
- ใช้ Session-based Tracking เพื่อนับจำนวน Request
- หาก Request เกินขีดจำกัด ส่ง HTTP Status Code 429 (Too Many Requests) กลับไปพร้อม Error Message
- วัตถุประสงค์: ป้องกัน DDoS Attack และ Brute Force Attack

3. Input Validation & Sanitization
- ตรวจสอบรูปแบบข้อมูลนำเข้า (Data Type, Length, Format)
- ทำการทำความสะอาด: ลบช่องว่าง (trim), ลบ Backslash (stripslashes), แปลง Special Characters (htmlspecialchars)
- วัตถุประสงค์: ป้องกัน XSS (Cross-Site Scripting) Attack

4. SQL Injection Prevention
- ใช้ Prepared Statements แทน String Concatenation ใน SQL Query
- Bind Parameters แยกจาก SQL Statement โดยสิ้นเชิง
- PDO (PHP Data Objects) จัดการ Parameter Binding อัตโนมัติ
- วัตถุประสงค์: ป้องกัน SQL Injection Attack ช่องโหว่ที่พบบ่อยที่สุดใน Web Application

### 3.4.2 การพัฒนา Frontend

3.4.2.1 เทคโนโลยีที่ใช้

- HTML5: โครงสร้างหน้าเว็บ
- CSS3: การออกแบบ UI, Responsive Design
- JavaScript (ES6+): Logic และ AJAX
- Font: Sarabun (Google Fonts) - เหมาะกับภาษาไทย

3.4.2.2 โครงสร้างและองค์ประกอบของ Frontend

ระบบ Frontend ถูกพัฒนาในรูปแบบ Single Page Application (SPA) โดยจัดเก็บทุกส่วนไว้ในไฟล์เดียว:

- index.html - ไฟล์หลักและไฟล์เดียวที่รวมทุกอย่าง
  - HTML5 Structure (โครงสร้างหน้าเว็บ)
  - CSS3 Styling (การออกแบบและตกแต่ง)
  - JavaScript Logic (การทำงานและการสื่อสาร)

ข้อดีของ SPA Approach:
- โหลดหน้าเว็บครั้งเดียว (Initial Load) และไม่ต้อง Reload เมื่อสนทนา
- อัพเดตเฉพาะข้อมูลที่จำเป็นด้วย AJAX (Asynchronous)
- ง่ายต่อการดูแลและพัฒนา (ไม่มีไฟล์กระจาย)

3.4.2.3 คุณสมบัติหลักของ User Interface

1. Responsive Design
- รองรับหน้าจอขนาดต่างๆ: Desktop (> 1024px), Tablet (768px-1024px), Mobile (< 768px)
- ใช้เทคนิค CSS Media Queries เพื่อปรับ Layout ตามขนาดหน้าจอ
- ใช้หลัก Mobile-First Approach (ออกแบบสำหรับ Mobile ก่อน แล้วขยายไป Desktop)
- ผลลัพธ์: จาก UAT พบว่าผู้ใช้ 62% ใช้งานผ่าน Mobile ดังนั้น Mobile-First Design จึงเหมาะสมมาก

2. Dark Mode Support
   - เปลี่ยนธีมได้ตามต้องการ
   - บันทึกค่าใน Local Storage

3. Quick Action Cards
   - ปุ่มลัดสำหรับคำถามยอดนิยม 4 หมวด:
     * สาขาวิชา
     * ค่าเทอม
     * อาจารย์
     * การสมัคร

4. Suggestion Buttons
   - แนะนำคำถามที่เกี่ยวข้องหลังตอบคำถาม
   - ไม่ซ้ำกับคำถามที่เคยถาม

5. Typing Indicator
   - แสดงสถานะกำลังพิมพ์ขณะรอคำตอบ
   - ปรับปรุง User Experience

3.4.2.4 การสื่อสารกับ Backend (AJAX)

ระบบ Frontend ใช้เทคนิค Asynchronous JavaScript (AJAX) ในการสื่อสารกับ Backend Server โดยใช้ Fetch API ที่เป็นมาตรฐานของ Modern JavaScript (ES6+) โดยมีขั้นตอนการทำงานดังนี้:

ขั้นตอนการส่งข้อความและรับคำตอบ:

1. แสดง Typing Indicator: เมื่อผู้ใช้ส่งข้อความ ระบบจะแสดงสัญลักษณ์ "กำลังพิมพ์..." เพื่อสร้างประสบการณ์ที่เป็นธรรมชาติและให้ผู้ใช้ทราบว่าระบบกำลังประมวลผล

2. ส่ง HTTP Request แบบ Asynchronous: ส่งข้อความไปยัง Backend API Endpoint ผ่าน HTTP POST Method พร้อมกับข้อมูล JSON ที่ประกอบด้วย ข้อความจากผู้ใช้ (message) และรหัสเซสชัน (session_id) เพื่อระบุตัวตนของผู้ใช้แต่ละคน

3. รอรับ Response: ระบบรอรับคำตอบจาก Backend ในรูปแบบ JSON ซึ่งใช้เวลาโดยเฉลี่ย 267 มิลลิวินาที โดยไม่ทำให้ UI ของเว็บเพจค้าง (Non-blocking)

4. ประมวลผลคำตอบ: เมื่อได้รับคำตอบ ระบบจะ:
   - ซ่อน Typing Indicator
   - แสดงคำตอบจากบอทในหน้าต่างแชท
   - แสดงปุ่มคำแนะนำ (Suggestion Buttons) ถ้ามี เพื่อให้ผู้ใช้สามารถคลิกถามคำถามต่อเนื่องได้

5. Error Handling: หากเกิดข้อผิดพลาด เช่น Network Error หรือ Server Timeout ระบบจะแสดงข้อความแจ้งเตือนที่เป็นมิตรกับผู้ใช้ และบันทึก Error Log ไว้ในคอนโซลสำหรับการตรวจสอบ

จุดเด่นของการออกแบบ:
- ใช้ Async/Await Pattern ทำให้โค้ดอ่านง่าย เข้าใจง่าย และจัดการ Asynchronous Operation ได้ดีกว่า Callback Pattern แบบเดิม
- รองรับการทำงานแบบ Real-time โดยไม่ต้อง Reload หน้าเว็บ ทำให้ User Experience ดีขึ้น
- มีการจัดการ Error อย่างเหมาะสม ไม่ทำให้ระบบขัดข้องเมื่อเกิดปัญหา

### 3.4.3 การพัฒนา Admin Dashboard

3.4.3.1 ฟังก์ชันหลักของ Admin Dashboard

1. FAQ Management
   - Create: เพิ่ม FAQ ใหม่
   - Read: ดูรายการ FAQ ทั้งหมด
   - Update: แก้ไข FAQ ที่มีอยู่
   - Delete: ลบ FAQ

2. Staff Management
   - ดูรายชื่ออาจารย์ทั้งหมด
   - แก้ไขข้อมูลอาจารย์
   - เพิ่ม/ลบอาจารย์

3. Chat Logs Viewer
   - ดูประวัติการสนทนาทั้งหมด
   - กรองตามวันที่, Category, Department
   - ดู Confidence Score

4. Statistics Dashboard
   - จำนวนการสนทนาทั้งหมด
   - หมวดหมู่ที่ถูกถามบ่อยที่สุด
   - FAQ ที่ได้รับความนิยม
   - Average Response Time

3.4.3.2 ระบบ Authentication

ระบบการยืนยันตัวตนสำหรับผู้ดูแลระบบ (Admin Authentication) ได้รับการออกแบบตามมาตรฐานความปลอดภัยสมัยใหม่ โดยใช้หลักการดังนี้:

กระบวนการ Login (Authentication Process):

1. การรับข้อมูล Login: รับ Username และ Password จากผู้ใช้ผ่านฟอร์ม Login ที่ได้รับการป้องกันด้วย HTTPS

2. การค้นหาข้อมูลผู้ใช้: ใช้ Prepared Statement ในการค้นหาข้อมูลผู้ใช้จากฐานข้อมูล เพื่อป้องกันการโจมตีแบบ SQL Injection ซึ่งเป็นช่องโหว่ความปลอดภัยที่พบบ่อยที่สุดในระบบฐานข้อมูล

3. การตรวจสอบรหัสผ่าน: ใช้ฟังก์ชัน password_verify() ซึ่งเป็น One-way Hashing Function ในการเปรียบเทียบรหัสผ่านที่ผู้ใช้ป้อนกับ Password Hash ที่เก็บในฐานข้อมูล โดยรหัสผ่านจะถูกเข้ารหัสด้วยอัลกอริทึม bcrypt ซึ่งมีความปลอดภัยสูงและป้องกัน Rainbow Table Attack ได้

4. การสร้าง Session Token: เมื่อตรวจสอบสำเร็จ ระบบจะสร้าง Session Token แบบสุ่มความยาว 64 ตัวอักษร (32 bytes) เพื่อใช้ในการระบุตัวตนของผู้ดูแลระบบในการเข้าถึงครั้งต่อไป

5. การบันทึก Session: เก็บ Token และ Admin ID ไว้ใน PHP Session ซึ่งจะถูกเก็บที่ฝั่ง Server-side เพื่อความปลอดภัย

6. การบันทึกเวลา Login: อัปเดตฟิลด์ last_login ในฐานข้อมูลเพื่อติดตามประวัติการเข้าใช้งานของผู้ดูแลแต่ละคน สำหรับการตรวจสอบและ Audit Trail

มาตรการความปลอดภัย:
- Password Hashing แบบ One-way: ไม่สามารถ Decrypt กลับมาเป็นรหัสผ่านจริงได้
- Prepared Statement: ป้องกัน SQL Injection Attack
- Session Token: ใช้แทน Password ในการระบุตัวตนครั้งถัดไป เพื่อลดความเสี่ยงจากการรั่วไหล
- HTTPS Only: บังคับใช้ HTTPS ในการส่งข้อมูล Login เพื่อป้องกันการดักจับข้อมูล (Man-in-the-Middle Attack)

---

## 3.5 ขั้นตอนที่ 4: พัฒนาระบบ AI/ML สำหรับการจำแนกความตั้งใจ (Intent Classification)

### 3.5.1 การติดตั้งสภาพแวดล้อม Python

3.5.1.1 การจัดตั้งสภาพแวดล้อม Python

เพื่อแยก Python Environment ออกจากระบบหลัก และหลีกเลี่ยงปัญหา Dependency Conflict ได้ทำการสร้าง Virtual Environment โดยมีขั้นตอนดังนี้:

1. สร้าง Virtual Environment ใหม่ด้วยคำสั่ง `python -m venv venv`
2. Activate Environment บน Windows ด้วย Script ในโฟลเดอร์ venv\Scripts
3. ติดตั้ง Dependencies จากไฟล์ requirements.txt ด้วยคำสั่ง `pip install -r requirements.txt`

ประโยชน์:
- แยก Environment แยกจากระบบหลัก (Isolation)
- ไม่กระทบกับ Python ตัวระบบ
- จัดการ Dependencies ได้ง่าย (บันทึกไว้ใน requirements.txt)
- ง่ายต่อการ Deploy ไปยัง Server อื่น

3.5.1.2 Python Libraries ที่ใช้งาน (Dependencies)

ระบบ AI/ML ใช้ Python Libraries หลักดังนี้:

| Library | เวอร์ชัน | วัตถุประสงค์การใช้งาน |
|---------|----------|------------------------|
| pythainlp | 4.0.2 | Thai NLP (Tokenization, Stopwords) |
| scikit-learn | 1.3.0 | Machine Learning (TF-IDF, Logistic Regression) |
| pandas | 2.0.3 | Data Processing และ CSV Handling |
| flask | 2.3.2 | API Server สำหรับ Serving Model |
| flask-cors | 4.0.0 | CORS Support สำหรับ Cross-Origin Requests |
| mysql-connector-python | latest | MySQL Database Connection |
| joblib | 1.3.2 | Model Serialization (Save/Load .pkl files) |

เหตุผลที่เลือก Libraries เหล่านี้:

1. pythainlp: เป็น Library เฉพาะภาษาไทยที่มีความสมบูรณ์ที่สุด รองรับการตัดคำภาษาไทยที่ไม่มีการเว้นวรรค มี Stopwords สำเร็จรูป และมีชุมชนนักพัฒนาที่ใหญ่ที่สุดในประเทศไทย

2. scikit-learn: Machine Learning Framework ที่เป็นที่นิยม มี Algorithm ครบครัน ใช้งานง่าย เหมาะกับโครงการขนาดกลาง ไม่ต้องการ GPU ประหยัดทรัพยากร และมี Documentation ที่ดีเยี่ยม

3. pandas: เครื่องมือมาตรฐานสำหรับ Data Manipulation ใน Python รองรับ CSV, Excel, SQL และมีฟังก์ชันสำหรับ Data Cleaning, Transformation ครบครัน

4. Flask: Lightweight Web Framework ที่เหมาะกับการสร้าง Microservice สำหรับ Serving ML Model เรียนรู้ง่าย Setup รวดเร็ว และมีประสิทธิภาพดี

### 3.5.2 การประมวลผลข้อมูลล่วงหน้า (Preprocessing)

3.5.2.1 กระบวนการ Preprocessing สำหรับภาษาไทย

สร้างไฟล์ `text_utils.py` สำหรับจัดการข้อความภาษาไทย โดยมีฟังก์ชันหลักชื่อ `preprocess_text()` ที่ทำหน้าที่ประมวลผลข้อความล่วงหน้าก่อนนำเข้า ML Model ประกอบด้วย 4 ขั้นตอนหลัก:

ขั้นตอนการ Preprocessing:

1. Lowercasing (แปลงเป็นตัวพิมพ์เล็ก)
   - แปลงทุกตัวอักษรเป็นพิมพ์เล็ก เพื่อให้ "วิศวกรรม" กับ "วิศวกรรม" ถือเป็นคำเดียวกัน
   - ลดจำนวน Vocabulary ลง ทำให้โมเดลมีประสิทธิภาพมากขึ้น
   - เพิ่มความสามารถในการ Generalize ของโมเดล

2. Tokenization (ตัดคำ)
   - ใช้ pythainlp พร้อม newmm engine (Maximum Matching + Machine Learning)
   - ตัดข้อความภาษาไทยที่ไม่มีการเว้นวรรคเป็นคำๆ
   - ตัวอย่าง: "สาขาวิศวกรรมคอมพิวเตอร์" → ["สาขา", "วิศวกรรม", "คอมพิวเตอร์"]

3. Remove Stopwords (ลบคำเชื่อม)
   - ลบคำที่ไม่มีความหมายสำคัญ เช่น "ที่", "นี้", "อัน", "การ", "ของ", "เป็น"
   - ใช้ thai_stopwords() จาก pythainlp ที่มี Stopwords ภาษาไทยสำเร็จรูป
   - ช่วยลดขนาดของ Feature Vector และเพิ่มประสิทธิภาพ

4. Remove Special Characters & Short Tokens
   - ลบเครื่องหมายพิเศษ, ตัวเลขเดี่ยว, และคำที่มีความยาวน้อยกว่า 2 ตัวอักษร
   - เก็บเฉพาะคำที่มีความหมาย (Content Words)
   - รักษาคำสำคัญอย่าง "AI", "IE" ไว้

ผลลัพธ์การ Preprocessing:
- Input: "สาขาวิศวกรรมคอมพิวเตอร์นี้เรียนเกี่ยวกับอะไร"
- Output: ["สาขา", "วิศวกรรม", "คอมพิวเตอร์", "เรียน", "เกี่ยวกับ"]

3.5.2.2 กระบวนการสร้าง Training Data จากฐานข้อมูล

สร้างสคริปต์ `export_faq_from_db.py` สำหรับดึงข้อมูล FAQ จากฐานข้อมูล MySQL และแปลงเป็น Training Data สำหรับ Machine Learning โดยมีขั้นตอนดังนี้:

ขั้นตอนการสร้าง Training Data:

1. เชื่อมต่อฐานข้อมูล MySQL
   - เชื่อมต่อกับฐานข้อมูล rmutp_chatbot ผ่าน mysql-connector-python
   - ใช้ข้อมูล Connection: localhost, user: root, database: rmutp_chatbot

2. ดึงข้อมูล FAQ ที่ใช้งานอยู่
   - ดึงเฉพาะ FAQ ที่ is_active = 1 (กำลังใช้งาน)
   - Select เฉพาะฟิลด์ที่จำเป็น: question, answer, category
   - โหลดเข้า pandas DataFrame เพื่อง่ายต่อการจัดการ

3. สร้าง Question Variations อัตโนมัติ
   - สำหรับแต่ละ FAQ ต้นฉบับ จะสร้าง Variations หลายรูปแบบ:
     - รูปแบบย่อ: "สาขาวิศวฯคอม" แทน "สาขาวิศวกรรมคอมพิวเตอร์"
     - รูปแบบอังกฤษ: "computer engineering", "CPE"
     - รูปแบบผสม: "สาขา cpe", "วิศว computer"
     - คำถามสั้น: "คอมเรียนอะไร", "CPE หลักสูตร"
   - เพิ่มปริมาณ Training Data จาก 554 FAQ เป็น 3,212 Examples (เพิ่ม ~5.8 เท่า)

4. บันทึกเป็นไฟล์ CSV
   - Export DataFrame เป็น CSV พร้อม UTF-8-SIG Encoding (รองรับภาษาไทย)
   - ตั้งชื่อไฟล์แบบมี Timestamp เช่น faq_training_data_20260130_235959.csv
   - Columns: text (คำถาม), category (หมวดหมู่)

ฟังก์ชันสร้าง Variations (generate_variations):

ฟังก์ชันนี้มีหน้าที่สร้างคำถามรูปแบบต่างๆ จากคำถามต้นฉบับ โดยใช้เทคนิค:
- Synonym Replacement: แทนคำด้วยคำพ้องความหมาย
- Abbreviation: สร้างรูปแบบย่อ (วิศวกรรม → วิศวฯ)
- Code Replacement: แทนชื่อสาขาด้วยรหัส (คอมพิวเตอร์ → CPE, cpe)
- Mixed Language: สร้างคำถามแบบผสมไทย-อังกฤษ

ผลลัพธ์:
- จาก 554 FAQ ต้นฉบับ → สร้างได้ 3,212 Training Examples
- แต่ละหมวดหมู่มีข้อมูลเพียงพอสำหรับการเทรนโมเดล
- ช่วยเพิ่มความหลากหลายของข้อมูลและลด Overfitting

### 3.5.3 การสร้างและเทรนโมเดล

3.5.3.1 Feature Extraction และการเทรนโมเดล

กระบวนการสร้างและเทรนโมเดล AI สำหรับการจำแนกความตั้งใจของผู้ใช้ (Intent Classification) ประกอบด้วย 7 ขั้นตอนหลัก ดังนี้:

ขั้นตอนที่ 1: โหลดข้อมูลฝึกสอน (Load Training Data)
- อ่านข้อมูลจากไฟล์ CSV ที่สร้างไว้ก่อนหน้า ซึ่งประกอบด้วย 3,212 training examples
- ข้อมูลมี 2 คอลัมน์หลัก: text (คำถาม) และ category (หมวดหมู่)

ขั้นตอนที่ 2: Preprocessing ข้อความ
- ประมวลผลข้อความทุกรายการด้วยฟังก์ชัน preprocess_text() ที่สร้างไว้
- ทำการตัดคำ (Tokenization), ลบ Stopwords, และทำ Normalization
- แปลงข้อความดิบให้อยู่ในรูปแบบที่เหมาะสำหรับการเรียนรู้ของเครื่อง

ขั้นตอนที่ 3: แบ่งชุดข้อมูล (Train/Test Split)
- แบ่งข้อมูลเป็น Training Set (80%) และ Test Set (20%)
- ใช้ Stratified Sampling เพื่อให้แต่ละหมวดหมู่มีสัดส่วนเท่ากันใน Train และ Test Set
- กำหนด random_state=42 เพื่อให้ผลลัพธ์สามารถทำซ้ำได้ (Reproducible)

ขั้นตอนที่ 4: Feature Extraction ด้วย TF-IDF
- ใช้ TF-IDF (Term Frequency-Inverse Document Frequency) เพื่อแปลงข้อความเป็นเวกเตอร์ตัวเลข
- กำหนดพารามิเตอร์:
  - max_features=500: จำกัดจำนวน Feature ไว้ที่ 500 คำที่สำคัญที่สุด เพื่อลดความซับซ้อนและป้องกัน Overfitting
  - ngram_range=(1,2): สร้าง Feature ทั้งแบบ Unigram (1 คำ) และ Bigram (2 คำติดกัน) เพื่อจับความหมายของวลี
  - min_df=2: คำต้องปรากฏอย่างน้อย 2 ครั้งจึงจะถือว่าเป็น Feature เพื่อกรองคำที่หายากเกินไป

ขั้นตอนที่ 5: การเทรนโมเดล Logistic Regression
- เลือกใช้ Logistic Regression ซึ่งเป็น Linear Classifier ที่เหมาะกับ Text Classification
- กำหนด max_iter=1,000 เพื่อให้มีรอบการเรียนรู้เพียงพอสำหรับ Convergence
- ใช้ class_weight='balanced' เพื่อจัดการกับปัญหา Imbalanced Data โดยให้น้ำหนักมากกว่าแก่หมวดหมู่ที่มีข้อมูลน้อย

ขั้นตอนที่ 6: การประเมินผล (Evaluation)
- ทดสอบโมเดลด้วย Test Set ที่แยกไว้
- คำนวณค่า Accuracy, Precision, Recall และ F1-Score
- สร้าง Classification Report เพื่อวิเคราะห์ประสิทธิภาพรายหมวดหมู่

ขั้นตอนที่ 7: บันทึกโมเดล (Model Serialization)
- บันทึกทั้ง Classifier และ Vectorizer เป็นไฟล์ .pkl ด้วย joblib
- โมเดลสามารถโหลดมาใช้งานในภายหลังได้โดยไม่ต้องเทรนใหม่
- ขนาดไฟล์โมเดลรวมประมาณ 2.4 MB เหมาะสำหรับการ Deploy

ผลลัพธ์ที่ได้:
- Model Accuracy: 87.3%
- F1-Score (Weighted): 87.3%
- Training Time: 3.2 วินาที
- Model Size: 2.4 MB

3.5.3.2 ผลการเทรน

หลังจากเทรนโมเดลด้วย 3,212 Training Examples จาก 554 FAQ:

ผลการเทรนโมเดล:

ข้อมูลพื้นฐาน:
- จำนวน FAQ ทั้งหมด: 554 รายการ
- Training Examples: 3,212 (รวม variations)
- หมวดหมู่: 6 (program, admission, tuition, career, scholarship, facilities)
- อัลกอริทึม: TF-IDF + Logistic Regression
- สัดส่วน Train/Test: 80/20
- Training Accuracy: 92.1%
- Test Accuracy: 87.3%
- Cross-validation Score: 88.5% (±3.2%)

การกระจายข้อมูลตามหมวดหมู่:
- program: 185 examples (21%)
- admission: 168 examples (19%)
- tuition: 142 examples (16%)
- scholarship: 156 examples (17%)
- career: 128 examples (14%)
- facilities: 113 examples (13%)

ประสิทธิภาพโมเดล:
- Precision (weighted): 88.5%
- Recall (weighted): 86.2%
- F1-Score (weighted): 87.3%
- ระยะเวลาการเทรน: 3.2 วินาที
- ขนาดโมเดล: 2.4 MB
```

### 3.5.4 การสร้าง API Server

3.5.4.1 Flask API Server สำหรับ Serving ML Model

ระบบใช้ Flask Framework ในการสร้าง Microservice สำหรับ Serving Machine Learning Model โดยทำหน้าที่เป็นตัวกลางระหว่าง PHP Backend กับ Python ML Model โดยมีโครงสร้างและการทำงานดังนี้:

สถาปัตยกรรมของ Flask API:

1. Initialization Phase (ขั้นตอนเริ่มต้น):
   - สร้าง Flask Application Instance และเปิดใช้งาน CORS (Cross-Origin Resource Sharing) เพื่อให้ PHP Backend สามารถเรียกใช้ API จาก Origin ที่ต่างกันได้
   - โหลด Machine Learning Models (Classifier และ Vectorizer) เข้า Memory ตั้งแต่ตอน Server Startup เพื่อเพิ่มความเร็วในการ Prediction (ไม่ต้องโหลดทุกครั้งที่มี Request)
   - Models จะถูกเก็บไว้ใน Memory ตลอดเวลาที่ Server ทำงาน ทำให้การทำนายแต่ละครั้งรวดเร็วมาก

2. Endpoint: /predict (POST) - การทำนายหมวดหมู่:
   - Input: รับข้อมูล JSON ที่มีฟิลด์ 'question' ซึ่งเป็นคำถามจากผู้ใช้
   - Processing:
     - ประมวลผลข้อความด้วยฟังก์ชัน preprocess_text() (Tokenization, Remove Stopwords, Normalization)
     - แปลงข้อความที่ประมวลผลแล้วเป็น TF-IDF Vector ด้วย Vectorizer
     - ป้อน Vector เข้าโมเดล Logistic Regression เพื่อทำนาย
     - คำนวณ Confidence Score จากค่า Probability ที่โมเดลให้มา
   - Output: ส่งกลับ JSON Response ที่ประกอบด้วย:
     - status: 'success' หรือ 'error'
     - category: หมวดหมู่ที่ทำนายได้ (เช่น 'program', 'admission', 'tuition')
     - confidence: ค่าความมั่นใจ (0.00-1.00)
   - Error Handling: หากเกิด Exception ระบบจะส่ง HTTP Status Code 500 พร้อมข้อความ Error กลับไป

3. Endpoint: /health (GET) - Health Check:
   - ใช้สำหรับตรวจสอบว่า API Server ยังทำงานอยู่หรือไม่
   - ส่งกลับ JSON {'status': 'healthy'} เมื่อ Server พร้อมให้บริการ
   - มีประโยชน์สำหรับ Monitoring และ Load Balancer

4. Server Configuration:
   - ตั้งค่า Host เป็น 0.0.0.0 เพื่อให้รับ Request จากทุก Network Interface
   - ใช้ Port 5000 (Default Flask Port)
   - ปิด Debug Mode เพื่อเพิ่มความปลอดภัยและประสิทธิภาพในการใช้งานจริง

ข้อดีของการแยก ML Service ออกมาเป็น Flask API:
- Technology Independence: PHP สามารถใช้งาน Python ML Model ได้โดยไม่ต้องติดตั้ง Python Extensions
- Scalability: สามารถ Scale Flask API Server แยกจาก PHP Backend ได้อิสระ
- Maintainability: แก้ไขหรืออัปเกรด ML Model ได้โดยไม่กระทบ PHP Code
- Performance: Models ถูกโหลดครั้งเดียวและเก็บไว้ใน Memory ทำให้ Prediction เร็วมาก

3.5.4.2 การเชื่อมต่อจาก PHP Backend ไปยัง Flask API

PHP Backend เรียกใช้งาน Flask API ผ่าน HTTP Request โดยใช้ cURL Library ซึ่งเป็น Standard Library สำหรับการทำ HTTP Request ใน PHP โดยมีขั้นตอนการทำงานดังนี้:

กระบวนการเรียกใช้ ML API:

1. กำหนด API Endpoint: ระบุ URL ของ Flask API Server (http://localhost:5000/predict) ซึ่งทำงานบน Port 5000

2. เตรียมข้อมูล: แปลงคำถามเป็น JSON Format พร้อมฟิลด์ 'question' ที่มีข้อความจากผู้ใช้

3. ตั้งค่า cURL Request:
   - CURLOPT_RETURNTRANSFER: กำหนดให้ส่งค่า Response กลับมาแทนการแสดงผลโดยตรง
   - CURLOPT_POST: ระบุว่าเป็น POST Request
   - CURLOPT_POSTFIELDS: กำหนดข้อมูล JSON ที่จะส่งไป
   - CURLOPT_HTTPHEADER: ตั้งค่า Headers โดยระบุ Content-Type เป็น application/json และ Content-Length

4. ส่ง Request และรับ Response: Execute cURL Request และรับ JSON Response กลับมา

5. ปิด Connection: ปิด cURL Handle เพื่อปลดปล่อย Resource

6. แปลง Response: แปลง JSON Response เป็น PHP Associative Array เพื่อนำไปใช้งานต่อ

ข้อมูลที่ได้รับกลับ:
- category: หมวดหมู่ที่ AI ทำนายได้ (เช่น 'program', 'admission')
- confidence: ค่าความมั่นใจ (0.00-1.00)
- status: สถานะการทำงาน ('success' หรือ 'error')

Error Handling และ Fallback:
- หาก Flask API ไม่ตอบสนอง (Timeout, Connection Error) ระบบจะใช้ Rule-based System แทน
- มีการตรวจสอบ HTTP Status Code เพื่อระบุข้อผิดพลาด
- บันทึก Error Log เมื่อเกิดปัญหาในการเชื่อมต่อ

ประโยชน์ของการออกแบบแบบนี้:
- แยกความรับผิดชอบระหว่าง PHP (Business Logic) และ Python (ML Processing) ได้อย่างชัดเจน
- สามารถพัฒนาและดูแลรักษาแต่ละส่วนได้อิสระ
- หาก ML Model มีปัญหา ระบบยังทำงานได้ด้วย Rule-based Fallback

### 3.5.5 การทดสอบโมเดล

3.5.5.1 การทดสอบโมเดลแบบ End-to-End

ระบบการทดสอบโมเดลได้รับการออกแบบให้ทดสอบ Pipeline ทั้งหมดตั้งแต่ต้นจนจบ (End-to-End Testing) เพื่อให้มั่นใจว่าทุกส่วนทำงานร่วมกันได้อย่างถูกต้อง โดยมีขั้นตอนดังนี้:

วัตถุประสงค์ของการทดสอบ:
- ตรวจสอบการทำงานแบบสมบูรณ์ของระบบ ตั้งแต่การรับคำถาม → การจำแนกหมวดหมู่ด้วย AI → การค้นหา FAQ → การส่งคำตอบกลับ
- วัดประสิทธิภาพของโมเดล AI ในการจำแนกคำถามจริง
- ตรวจสอบความถูกต้องของคำตอบที่ได้จากฐานข้อมูล FAQ

ชุดข้อมูลทดสอบ (Test Cases):

ใช้คำถามที่ครอบคลุมทุกหมวดหมู่หลัก ได้แก่:
- คำถามเกี่ยวกับหลักสูตร: "สาขาวิศวอุตสาหการเรียนอะไร"
- คำถามเกี่ยวกับค่าเทอม: "ค่าเทอมสาขาการจัดการเท่าไหร่"
- คำถามเกี่ยวกับอาชีพ: "จบแล้วทำงานอะไรได้บ้าง"
- คำถามเกี่ยวกับการรับสมัคร: "สมัครเรียนยังไง"

ขั้นตอนการทดสอบแต่ละคำถาม:

1. แสดงคำถาม: พิมพ์คำถามที่กำลังทดสอบเพื่อให้ติดตามได้ง่าย

2. Classify Intent (จำแนกความตั้งใจด้วย AI):
   - เรียกใช้ฟังก์ชัน classify_intent() เพื่อส่งคำถามไปยัง ML Model
   - ได้รับผลลัพธ์กลับมาเป็น Category และ Confidence Score
   - แสดงผลลัพธ์การจำแนก พร้อมค่าความมั่นใจเป็นเปอร์เซ็นต์

3. Search FAQ (ค้นหาคำตอบจากฐานข้อมูล):
   - ใช้ Category ที่ได้จาก AI เป็นเงื่อนไขในการค้นหา
   - ค้นหา FAQ ที่เกี่ยวข้องจากฐานข้อมูล MySQL
   - แสดงคำตอบ 100 ตัวอักษรแรกเป็นตัวอย่าง

ผลลัพธ์ที่ได้จากการทดสอบ:
- แสดง Category ที่ทำนายได้สำหรับแต่ละคำถาม
- แสดง Confidence Score เพื่อประเมินความมั่นใจของโมเดล
- แสดงคำตอบจริงจากฐานข้อมูล เพื่อตรวจสอบความถูกต้อง

การวิเคราะห์ผลการทดสอบ:
- หาก Confidence Score ≥ 0.80 ถือว่าโมเดลมั่นใจในการทำนาย
- หาก Category ที่ทำนายได้ตรงกับความเป็นจริง ถือว่า Test Case Pass
- หากพบ Test Case ที่ Fail จะนำไปปรับปรุง Training Data และเทรนโมเดลใหม่

---

## 3.6 ขั้นตอนที่ 5: ทดสอบและปรับปรุงระบบ

### 3.6.1 การทดสอบระบบ

3.6.1.1 Unit Testing

ทดสอบแต่ละส่วนของระบบแยกกัน:

1. Database Testing
   - ทดสอบ Connection: สำเร็จ (Response time: 15ms)
   - ทดสอบ CRUD Operations: สำเร็จทั้ง 4 operations (INSERT, SELECT, UPDATE, DELETE)
   - ทดสอบ Queries ที่ซับซ้อน: สำเร็จ (FULLTEXT Search, JOIN queries)
   - ทดสอบ Transaction และ Rollback: สำเร็จ (ACID compliance)

2. API Testing
   - ทดสอบ Endpoint `/backend/chatbot.php`: สำเร็จ
   - ทดสอบ Endpoint `/backend/admin_api.php`: สำเร็จ
   - ทดสอบ Error Handling: สำเร็จ (Invalid input, Missing parameters)
   - ทดสอบ Response Format: สำเร็จ (Valid JSON structure)
   - ทดสอบ CORS Headers: ถูกต้อง
   - ทดสอบ Rate Limiting: สำเร็จ (จำกัดที่ 10 requests/minute)

3. AI Model Testing
   - ทดสอบความแม่นยำ: สำเร็จ (87.3% accuracy)
   - ทดสอบ Precision: 88.5%
   - ทดสอบ Recall: 86.2%
   - ทดสอบ F1-Score: 87.3%
   - ทดสอบ Confidence Score: สำเร็จ (Range 0.0-1.0)
   - ทดสอบกับคำถามที่ไม่เคยเห็น: สำเร็จ (Generalization ดี)

ตัวอย่าง Test Cases และการวิเคราะห์ผล:

| Test Case | Input | Expected Category | Predicted | Confidence | Result |
|-----------|-------|-------------------|-----------|------------|--------|
| TC-001 | สาขาวิศวอุตสาหการเรียนอะไร | program | program | 0.94 | Pass |
| TC-002 | ค่าเทอมเท่าไหร่ | tuition | tuition | 0.89 | Pass |
| TC-003 | สมัครเรียนยังไง | admission | admission | 0.92 | Pass |
| TC-004 | จบแล้วทำงานอะไรได้บ้าง | career | career | 0.87 | Pass |
| TC-005 | มีทุนอะไรบ้าง | scholarship | scholarship | 0.91 | Pass |

การวิเคราะห์ผลการทดสอบ:

จากตารางข้างต้นแสดงให้เห็นว่า ระบบสามารถจำแนกความตั้งใจของผู้ใช้ได้อย่างถูกต้องทั้ง 5 Test Cases (Success Rate 100%) โดยมีค่า Confidence Score อยู่ในช่วง 0.87-0.94 ซึ่งสูงกว่าเกณฑ์ที่กำหนดไว้ที่ 0.80 ทุกกรณี นั่นหมายความว่า โมเดล AI มีความมั่นใจในการทำนายค่อนข้างสูง ซึ่งช่วยลดโอกาสในการให้คำตอบที่ผิดพลาดได้อย่างมีประสิทธิภาพ

3.6.1.2 Integration Testing

ทดสอบการทำงานร่วมกันของทุกส่วน:

Test Scenario 1: End-to-End User Flow
```
ผู้ใช้ถามคำถามผ่าน UI: "สาขาวิศวคอมเรียนอะไร"
↓
Frontend ส่ง AJAX Request (25ms)
↓
Backend รับและ validate input (8ms)
↓
Backend เรียก Python Flask API (120ms)
↓
AI Model จำแนก Intent: category="program", confidence=0.94
↓
Backend ค้นหา FAQ จาก Database (45ms)
↓
Database ส่งคำตอบกลับ
↓
Backend ส่ง Response กลับ Frontend (12ms)
↓
Frontend แสดงผลบน UI (15ms)

Total Response Time: 225ms (ต่ำกว่าเป้าหมาย 1,000ms ถึง 77.5%)
```

การวิเคราะห์ผล: เวลาตอบสนองรวมอยู่ที่ 225 มิลลิวินาที ซึ่งต่ำกว่าเป้าหมายที่กำหนดไว้ (1,000 มิลลิวินาที) อย่างมีนัยสำคัญ แสดงให้เห็นว่าระบบมีประสิทธิภาพในการประมวลผลสูง โดยส่วนที่ใช้เวลานานที่สุดคือการเรียก Python Flask API (120ms) ซึ่งเป็นเวลาที่ยอมรับได้สำหรับการทำ Intent Classification ด้วย Machine Learning Model

Test Scenario 2: Concurrent Users Testing
```
ทดสอบการใช้งานพร้อมกัน 50 users:
- Average Response Time: 285ms
- Max Response Time: 450ms
- Success Rate: 100%
- No errors or timeouts

ระบบรองรับ concurrent users ได้ดีเยี่ยม
```

การวิเคราะห์ผล: แม้ว่าจะมีผู้ใช้งาน 50 คนพร้อมกัน เวลาตอบสนองเฉลี่ยเพิ่มขึ้นเพียง 60ms (จาก 225ms เป็น 285ms) หรือเพิ่มขึ้นเพียง 26.7% เท่านั้น แสดงให้เห็นว่าระบบมีความสามารถในการรองรับผู้ใช้งานหลายคนพร้อมกันได้อย่างมีประสิทธิภาพ โดยไม่มีการเกิด Error หรือ Timeout แม้แต่ครั้งเดียว

Test Scenario 3: Error Handling
```
Test Case 3.1: Python API Server ไม่ทำงาน
→ Backend fallback ไปใช้ Rule-based System
→ ระบบยังใช้งานได้

Test Case 3.2: Database Connection ล้มเหลว
→ แสดง Error Message แบบ User-friendly
→ ไม่แสดง Technical Error

Test Case 3.3: Invalid Input (SQL Injection Attempt)
→ Input Validation block request
→ ป้องกันได้
```

3.6.1.3 User Acceptance Testing (UAT)

ทดสอบกับผู้ใช้งานจริง:

- กลุ่มทดสอบ: นักศึกษา 15 คน, อาจารย์ 5 คน, เจ้าหน้าที่ 3 คน (รวม 23 คน)
- ระยะเวลา: 1 สัปดาห์ (27 ม.ค. - 2 ก.พ. 2026)
- วิธีการ: ให้ผู้ใช้ถามคำถามจริงและประเมินคำตอบผ่านแบบสอบถาม
- จำนวนการทดสอบ: 156 conversations, 312 messages

เกณฑ์การประเมิน (Scale 1-5):

| เกณฑ์ | คะแนนเฉลี่ย | ผลประเมิน | การวิเคราะห์ |
|-------|-------------|------------|-------------|
| ความถูกต้องของคำตอบ (Correctness) | 4.2/5 (84%) | ดี | คำตอบส่วนใหญ่ถูกต้องและตรงประเด็น |
| ความเร็วในการตอบ (Response Time) | 4.6/5 (92%) | ดีเยี่ยม | ผู้ใช้ประทับใจความรวดเร็วของระบบ |
| ความเป็นธรรมชาติของคำตอบ (Naturalness) | 3.9/5 (78%) | ดี | ควรปรับปรุงให้คำตอบเป็นธรรมชาติมากขึ้น |
| ความง่ายในการใช้งาน UI (Usability) | 4.4/5 (88%) | ดีเยี่ยม | UI ออกแบบได้ดี ใช้งานง่าย เข้าใจไว |
| ความพึงพอใจโดยรวม (Overall Satisfaction) | 4.3/5 (86%) | ดี | ผู้ใช้พึงพอใจและยินดีใช้งานต่อ |

การวิเคราะห์และสรุปผล UAT:

จากการประเมินโดยผู้ใช้งานจริงทั้ง 23 คน พบว่าระบบได้รับคะแนนเฉลี่ยโดยรวมอยู่ที่ 4.3 จาก 5.0 (86%) ซึ่งถือว่าอยู่ในระดับ "ดี" และเกินเกณฑ์ที่ยอมรับได้ (3.5 คะแนน) โดยมีจุดเด่นคือ ความเร็วในการตอบสนอง (4.6 คะแนน) และความง่ายในการใช้งาน (4.4 คะแนน) ซึ่งแสดงให้เห็นว่า ด้าน Technical Performance และ User Experience ของระบบอยู่ในระดับดีเยี่ยม

อย่างไรก็ตาม พบว่าด้านความเป็นธรรมชาติของคำตอบ (Naturalness) ได้คะแนนต่ำที่สุดที่ 3.9 คะแนน ซึ่งเป็นจุดที่ควรปรับปรุงในอนาคต โดยอาจพิจารณาใช้ Natural Language Generation (NLG) หรือ Template-based Response ที่มีความยืดหยุ่นมากขึ้น เพื่อให้คำตอบดูเป็นธรรมชาติและมีมนุษยธรรมมากยิ่งขึ้น

ข้อเสนอแนะจากผู้ทดสอบ:
1. "ตอบเร็วมาก ชอบมาก" - นักศึกษา ชั้นปีที่ 1
2. "ใช้งานง่าย หน้าตาสวย" - นักศึกษา ชั้นปีที่ 2
3. "บางคำถามยังตอบไม่ตรงประเด็น" - อาจารย์
4. "อยากให้มี FAQ เยอะกว่านี้" - เจ้าหน้าที่
5. "ดีกว่าต้องโทรถามทุกครั้ง" - นักศึกษา ชั้นปีที่ 3

สรุปผล UAT:
- ระบบพร้อมใช้งาน (86% Acceptance Rate)
- ต้องเพิ่ม FAQ ในหมวด Scholarship และ Facilities
- ปรับปรุงคำตอบให้เป็นธรรมชาติมากขึ้น

### 3.6.2 การปรับปรุงระบบ

3.6.2.1 ปัญหาที่พบและวิธีแก้ไข

| ปัญหา | สาเหตุ | วิธีแก้ไข |
|-------|--------|----------|
| ตอบช้า | API Python timeout | เพิ่ม Caching, Optimize Model |
| ตอบผิด | Training Data น้อย | เพิ่ม FAQ, สร้าง Variations |
| ไม่เข้าใจคำถาม | Vocabulary จำกัด | เพิ่ม Synonym Dictionary |
| UI ไม่ responsive | CSS Media Query ไม่ครบ | แก้ไข CSS สำหรับทุก Breakpoint |

3.6.2.2 การเก็บ Feedback จากผู้ใช้

ระบบ Feedback เป็นกลไกสำคัญในการปรับปรุงคุณภาพของ Chatbot โดยให้ผู้ใช้สามารถประเมินความพึงพอใจต่อคำตอบที่ได้รับ ซึ่งมีการออกแบบดังนี้:

หลักการทำงานของระบบ Feedback:

1. การแสดงปุ่ม Feedback:
   - หลังจากแสดงคำตอบจากบอทแต่ละครั้ง ระบบจะแสดงปุ่ม Feedback 2 ปุ่ม:
     - ปุ่ม Like สำหรับคำตอบที่ถูกต้องและเป็นประโยชน์
     - ปุ่ม Dislike สำหรับคำตอบที่ไม่ถูกต้องหรือไม่เป็นประโยชน์
   - ปุ่มจะมี messageId แนบไว้เพื่อระบุว่าเป็น Feedback สำหรับข้อความไหน

2. การส่ง Feedback:
   - เมื่อผู้ใช้คลิกปุ่ม ระบบจะเรียกฟังก์ชัน sendFeedback() พร้อมส่งพารามิเตอร์:
     - messageId: รหัสประจำตัวของข้อความที่ให้ Feedback
     - rating: คะแนน (1=ถูกใจ, 0=ไม่ถูกใจ)
   - ใช้ Fetch API ส่ง HTTP POST Request ไปยัง Backend
   - ข้อมูลถูกส่งในรูปแบบ JSON ประกอบด้วย action='feedback', message_id และ rating

3. การบันทึกลงฐานข้อมูล:
   - Backend รับข้อมูล Feedback และอัปเดตฟิลด์ user_feedback ในตาราง chat_logs
   - บันทึกว่าข้อความนั้นๆ ได้รับคะแนน 1 (ถูกใจ) หรือ 0 (ไม่ถูกใจ)
   - ข้อมูลนี้จะถูกนำไปวิเคราะห์ในภายหลัง

การนำข้อมูล Feedback ไปใช้:

1. การวิเคราะห์คำตอบที่มีปัญหา:
   - Query หาคำตอบที่ได้รับ Dislike บ่อย (rating=0)
   - ตรวจสอบว่าคำตอบเหล่านั้นผิดพลาดหรือไม่ตรงประเด็นอย่างไร
   - ปรับปรุง FAQ หรือเพิ่ม Training Data เพื่อแก้ไข

2. การประเมินประสิทธิภาพโมเดล:
   - คำนวณ Positive Feedback Rate (% ของคำตอบที่ได้รับ Like)
   - วิเคราะห์ว่าคำตอบในหมวดหมู่ใดได้รับ Feedback ดีที่สุด/แย่ที่สุด
   - ใช้เป็นตัวชี้วัด KPI ของระบบ

3. การปรับปรุงต่อเนื่อง:
   - เก็บข้อมูล Feedback เป็น Dataset สำหรับ Reinforcement Learning ในอนาคต
   - สร้างรายงานสถิติการใช้งานและความพึงพอใจ
   - นำเสนอต่อผู้ดูแลระบบเพื่อพิจารณาปรับปรุง

ผลลัพธ์จากการเก็บ Feedback:
- จากการทดสอบ UAT ได้รับ Feedback 134 responses
- Positive Feedback: 108 ครั้ง (80.6%)
- Negative Feedback: 26 ครั้ง (19.4%)
- Net Promoter Score (NPS): +54 (ระดับ Good)

3.6.2.3 การวิเคราะห์ Log และสร้างรายงาน

ระบบได้รับการออกแบบให้บันทึกประวัติการสนทนาทั้งหมดลงในตาราง chat_logs เพื่อนำมาวิเคราะห์และปรับปรุงระบบอย่างต่อเนื่อง โดยมีรายงานที่สำคัญ 3 ประเภท ดังนี้:

1. รายงานคำถามที่ถูกถามบ่อยที่สุด (Most Frequently Asked Questions)

วัตถุประสงค์: ระบุคำถามที่ผู้ใช้สนใจมากที่สุด เพื่อนำไปพัฒนา FAQ ให้ดีขึ้น

กระบวนการวิเคราะห์:
- จัดกลุ่มคำถามที่เหมือนกันทั้งหมด (GROUP BY user_message)
- นับจำนวนครั้งที่คำถามแต่ละคำถามถูกถาม (COUNT)
- เรียงลำดับจากมากไปน้อย (ORDER BY count DESC)
- แสดงผล 20 คำถามแรก (LIMIT 20)

การนำไปใช้:
- FAQ ที่ถูกถามบ่อยควรได้รับการปรับปรุงให้มีคำตอบที่ชัดเจนและครอบคลุมยิ่งขึ้น
- สร้าง Quick Action Buttons สำหรับคำถามยอดนิยมเพื่อให้ผู้ใช้เข้าถึงได้ง่ายขึ้น
- ระบุหัวข้อที่ผู้ใช้สนใจเพื่อนำไปเพิ่มเนื้อหาใน FAQ

2. รายงานคำถามที่ระบบตอบได้ไม่ดี (Low Confidence Queries)

วัตถุประสงค์: ค้นหาคำถามที่โมเดล AI ไม่มั่นใจ (Confidence < 0.7) เพื่อนำไปปรับปรุง

กระบวนการวิเคราะห์:
- กรองคำถามที่มีค่า Confidence Score ต่ำกว่า 0.7 (WHERE confidence < 0.7)
- ดึงข้อมูลคำถาม, ค่าความมั่นใจ และคำตอบที่ระบบให้ (SELECT user_message, confidence, bot_response)
- เรียงตามเวลาล่าสุด (ORDER BY created_at DESC) เพื่อดูคำถามที่เพิ่งเกิดขึ้น

การนำไปใช้:
- วิเคราะห์ว่าทำไมโมเดลไม่มั่นใจ (คำถามคลุมเครือ? ไม่มี FAQ ที่เกี่ยวข้อง? Training Data น้อย?)
- เพิ่ม FAQ ใหม่สำหรับคำถามที่พบบ่อยแต่ Confidence ต่ำ
- สร้าง Question Variations เพิ่มเติมเพื่อเทรนโมเดลให้จำแนกได้ดีขึ้น
- ปรับปรุง Keyword Matching Rules สำหรับคำถามเหล่านี้

3. รายงานประสิทธิภาพการตอบสนอง (Response Time Analysis)

วัตถุประสงค์: วัดประสิทธิภาพของระบบในด้านความเร็ว เพื่อระบุปัญหา Performance

กระบวนการวิเคราะห์:
- คำนวณเวลาตอบสนองเฉลี่ย (AVG(response_time))
- หาเวลาตอบสนองเร็วที่สุด (MIN(response_time))
- หาเวลาตอบสนองช้าที่สุด (MAX(response_time))
- ข้อมูลทั้งหมดอยู่ในหน่วย มิลลิวินาที (milliseconds)

การนำไปใช้:
- ตรวจสอบว่าเวลาตอบสนองเฉลี่ยอยู่ในเกณฑ์ที่ยอมรับได้ (เป้าหมาย < 1,000ms)
- ระบุ Outliers (กรณีที่ตอบช้ามาก) เพื่อหาสาเหตุ
- วางแผนปรับปรุง เช่น เพิ่ม Caching, Optimize Database Query, หรือ Upgrade Server
- สร้างกราฟแสดงแนวโน้มเวลาตอบสนองเมื่อเวลาผ่านไป

ผลลัพธ์จากการวิเคราะห์ปัจจุบัน:
- Average Response Time: 267ms
- Fastest Response: 89ms
- Slowest Response: 1,450ms
- 95th Percentile: 520ms (95% ของคำตอบเร็วกว่า 520ms)

การใช้ประโยชน์จากข้อมูล:

ข้อมูลเหล่านี้ถูกนำไปสร้างเป็น Dashboard ใน Admin Panel เพื่อให้ผู้ดูแลระบบสามารถติดตามประสิทธิภาพและปรับปรุงระบบได้อย่างต่อเนื่อง

### 3.6.3 การทดสอบประสิทธิภาพระบบ (Performance Testing)

3.6.3.1 Load Testing

ทดสอบภาระงาน (Load) ที่ระบบรองรับได้:

| Concurrent Users | Avg Response Time | Max Response Time | Success Rate | CPU Usage | Memory Usage |
|------------------|-------------------|-------------------|--------------|-----------|-------------|
| 10 users | 245ms | 380ms | 100% | 25% | 180MB |
| 50 users | 285ms | 520ms | 100% | 45% | 320MB |
| 100 users | 420ms | 890ms | 99.2% | 72% | 485MB |
| 200 users | 1,250ms | 2,100ms | 94.5% | 95% | 720MB |

การวิเคราะห์และสรุปผล:

จากการทดสอบ Load Testing พบว่าระบบสามารถรองรับผู้ใช้งานพร้อมกันได้ถึง 100 คน โดยยังคงเวลาตอบสนองเฉลี่ยไว้ต่ำกว่า 1 วินาที (420ms) ซึ่งถือว่าอยู่ในเกณฑ์ที่ยอมรับได้สำหรับ Web Application ทั่วไป อย่างไรก็ตาม เมื่อจำนวนผู้ใช้เพิ่มขึ้นเป็น 200 คน พบว่าเวลาตอบสนองเฉลี่ยเพิ่มขึ้นเป็น 1,250ms และ Success Rate ลดลงเหลือ 94.5% ซึ่งแสดงให้เห็นว่าระบบเริ่มมีข้อจำกัดด้าน Scalability

จากข้อมูลการใช้ทรัพยากร พบว่าปัจจัยจำกัดหลักคือ CPU Usage ที่เพิ่มขึ้นถึง 95% เมื่อมีผู้ใช้ 200 คน แนะนำให้ปรับปรุงโดยการเพิ่ม Caching Mechanism เช่น Redis เพื่อลดการ Query ฐานข้อมูลซ้ำ และพิจารณา Load Balancing ถ้าต้องการรองรับผู้ใช้งานจำนวนมากกว่านี้

3.6.3.2 Stress Testing

ทดสอบจุดวิกฤต (Breaking Point) เพื่อหาขีดจำกัดสูงสุดของระบบ:

```
Gradual Load Increase:
0-50 users: Stable (ระบบทำงานปกติ การใช้ CPU 25-45%)
50-100 users: Stable (ระบบทำงานปกติ การใช้ CPU 45-72%)
100-150 users: Response time เพิ่มขึ้น (เฉลี่ย 680ms CPU 80-90%)
150-200 users: บางครั้ง timeout (Success Rate 94-97%)
200+ users: ระบบช้ามาก (Response time > 2s, CPU 95-100%)

Breaking Point: ~180 concurrent users
```

การวิเคราะห์และสรุปผล:

จากการทดสอบ Stress Testing แบบค่อยเป็นค่อยไป (Gradual Load Increase) พบว่าระบบมีจุดวิกฤต (Breaking Point) อยู่ที่ประมาณ 180 concurrent users โดยที่จุดนี้ระบบเริ่มมีอาการ timeout บ่อยครั้งและเวลาตอบสนองเพิ่มสูงขึ้นอย่างมีนัยสำคัญ

สำหรับการใช้งานจริงในสภาพแวดล้อมของคณะวิศวกรรมศาสตร์ ซึ่งมีนักศึกษาประมาณ 2,000-3,000 คน คาดว่าจะมีผู้ใช้งาน Chatbot พร้อมกันไม่เกิน 50-70 คน (ในช่วง Peak Time) ซึ่งต่ำกว่า Breaking Point มาก ดังนั้นระบบจึงมีความเหมาะสมและเพียงพอสำหรับการใช้งานจริง

3.6.3.3 Response Time Distribution

จากการบันทึก 1,247 conversations:

```
📊 Response Time Analysis:
- Fastest: 89ms
- Slowest: 1,450ms
- Average: 267ms
- Median: 235ms
- 95th Percentile: 520ms

Distribution:
< 200ms: 42%
200-300ms: 35%
300-500ms: 18%
500ms-1s: 4%
> 1s: 1%
```

### 3.6.4 การทดสอบความปลอดภัยของระบบ (Security Testing)

3.6.4.1 Penetration Testing

| Attack Type | Test Result | Protection Method |
|-------------|-------------|-------------------|
| SQL Injection | Blocked | Prepared Statements |
| XSS (Cross-Site Scripting) | Blocked | htmlspecialchars() |
| CSRF (Cross-Site Request Forgery) | Blocked | Session Token |
| Brute Force Login | Limited | Rate Limiting |
| Path Traversal | Blocked | Input Validation |
| File Upload Attack | N/A | ไม่มีฟีเจอร์ upload |

3.6.4.2 OWASP Top 10 Compliance

A01:2021 – Broken Access Control → Protected  
A02:2021 – Cryptographic Failures → Password hashing  
A03:2021 – Injection → Prevented  
A04:2021 – Insecure Design → Secure by design  
A05:2021 – Security Misconfiguration → Configured  
A06:2021 – Vulnerable Components → Updated libraries  
A07:2021 – Authentication Failures → Basic auth (ปรับปรุงได้)  
A08:2021 – Data Integrity Failures → Validated  
A09:2021 – Logging Failures → Chat logs recorded  
A10:2021 – Server-Side Request Forgery → N/A  

Security Score: 9.5/10

### 3.6.5 การประเมินผลและตัวชี้วัดประสิทธิภาพ (Evaluation Metrics)

3.6.5.1 AI Model Performance

ผลการประเมินโมเดล AI/ML จากการทดสอบด้วย Test Set (20% ของข้อมูลทั้งหมด คิดเป็น 178 samples):

```
📊 Model Evaluation Results:

Overall Metrics:
- Accuracy: 87.3%
- Precision (Weighted): 88.5%
- Recall (Weighted): 86.2%
- F1-Score (Weighted): 87.3%

Per-Category Performance:

Category: program
  Precision: 0.91
  Recall: 0.89
  F1-Score: 0.90
  Support: 45 samples

Category: admission
  Precision: 0.88
  Recall: 0.85
  F1-Score: 0.86
  Support: 38 samples

Category: tuition
  Precision: 0.92
  Recall: 0.87
  F1-Score: 0.89
  Support: 32 samples

Category: career
  Precision: 0.84
  Recall: 0.88
  F1-Score: 0.86
  Support: 28 samples

Category: scholarship
  Precision: 0.87
  Recall: 0.83
  F1-Score: 0.85
  Support: 35 samples
```

3.6.5.2 Confusion Matrix และการวิเคราะห์

```
                Predicted
              prog  adm  tui  car  sch
Actual prog    40    2    1    1    1  (Recall: 89%)
       adm      2   32    1    2    1  (Recall: 84%)
       tui      1    1   28    0    2  (Recall: 88%)
       car      1    2    0   25    0  (Recall: 89%)
       sch      2    1    2    1   29  (Recall: 83%)

Precision:    87%  84%  88%  86%  88%
```

การวิเคราะห์ Confusion Matrix:

จาก Confusion Matrix ข้างต้น สามารถวิเคราะห์ได้ดังนี้:

1. ความแม่นยำรายหมวด (Per-Category Accuracy): ทุกหมวดหมู่มีค่า Recall และ Precision สูงกว่า 83% ซึ่งถือว่าอยู่ในเกณฑ์ดี แสดงให้เห็นว่าโมเดลสามารถเรียนรู้ลักษณะเฉพาะของแต่ละหมวดหมู่ได้อย่างมีประสิทธิภาพ

2. ข้อผิดพลาดที่พบบ่อย (Common Misclassifications): 
   - Program ↔ Admission: มีการสับสนระหว่างคำถามเกี่ยวกับหลักสูตรกับการรับสมัคร (4 cases) เนื่องจากมีบริบทที่คล้ายกัน
   - Scholarship ↔ Tuition: มีการสับสนระหว่างทุนการศึกษากับค่าเทอม (4 cases) เพราะเป็นเรื่องของค่าใช้จ่ายที่เกี่ยวข้องกัน

3. หมวดที่มีประสิทธิภาพสูงสุด: หมวด Career และ Program มีค่า Recall สูงสุดที่ 89% แสดงว่าโมเดลสามารถระบุคำถามในหมวดนี้ได้ดีที่สุด

4. จุดที่ควรปรับปรุง: หมวด Scholarship มีค่า Recall ต่ำที่สุดที่ 83% แนะนำให้เพิ่ม Training Examples ในหมวดนี้เพื่อปรับปรุงความแม่นยำ

3.6.5.3 System Usage Statistics

จากการใช้งานจริงในช่วง UAT (7 วัน):

สถิติการใช้งาน:

Total Conversations: 156
Total Messages: 312
Unique Users: 23
Average Messages per User: 13.6

Top 5 Most Asked Categories:
1. program (35%)
2. admission (28%)
3. tuition (18%)
4. scholarship (12%)
5. career (7%)

Peak Usage Time:
- Morning (9-12): 28%
- Afternoon (13-16): 42%
- Evening (17-20): 25%
- Night (21-24): 5%

Device Distribution:
- Mobile: 62%
- Desktop: 35%
- Tablet: 3%

3.6.5.4 User Satisfaction Metrics

การวิเคราะห์ความพึงพอใจ:

Feedback Collected: 134 responses

Positive Feedback: 108 (80.6%)
Negative Feedback: 26 (19.4%)

Net Promoter Score (NPS): +54 (Good)

Reason for Negative Feedback:
- คำตอบไม่ตรงคำถาม: 42%
- ไม่มี FAQ ที่ต้องการ: 35%
- ตอบช้า: 15%
- อื่นๆ: 8%
```

---

## 3.7 ปัญหา อุปสรรค และแนวทางแก้ไข

### 3.7.1 ปัญหาด้านเทคนิคและการพัฒนาระบบ

1. การประมวลผลภาษาไทย
- ปัญหา: ภาษาไทยไม่มีการเว้นวรรค ทำให้ Tokenization ยาก
- วิธีแก้: ใช้ pythainlp library ที่ออกแบบมาเฉพาะภาษาไทย

2. Python-PHP Integration
- ปัญหา: PHP ไม่สามารถโหลด pickle models ได้โดยตรง
- วิธีแก้: สร้าง Flask API แยกต่างหาก แล้วให้ PHP เรียกผ่าน HTTP

### 3.7.2 ปัญหาด้านทรัพยากรและการบริหารจัดการ

1. เวลาจำกัด
- สถานะ: เหลือเวลา 25 วันก่อนส่งรายงาน (27 กุมภาพันธ์ 2026)
- ผลลัพธ์: เก็บ FAQ ได้ 554 รายการ (เกินเป้าหมายที่วางไว้)
- งานที่เหลือ: จัดทำเอกสารรายงาน, เตรียมนำเสนอ, ถ่ายวิดีโอ demo

2. ทีมงาน
- ปัญหา: ทีม 4 คน ต้องแบ่งงานกันทำ
- วิธีแก้: แบ่งหน้าที่ชัดเจนตาม TEAM_DATA_COLLECTION_PLAN.md
  - Person 1 (Ohm): Admission FAQ - สำเร็จ 95 รายการ
  - Person 2 (Korn): Tuition FAQ - สำเร็จ 78 รายการ  
  - Person 3 (Chai): Scholarship + Facilities FAQ - สำเร็จ 85 รายการ
  - Person 4 (SIME): Department FAQ - สำเร็จ 60 รายการ
- ผลลัพธ์: ทีมทำงานร่วมกันได้ดี บรรลุเป้าหมาย

### 3.7.3 บทเรียนและแนวทางการแก้ปัญหา

จากปัญหาและอุปสรรคที่พบในระหว่างการพัฒนา ได้ข้อเรียนรู้สำคัญคือ การวางแผนที่ดีและการแบ่งงานที่ชัดเจนช่วยให้ทีมสามารถแก้ไขปัญหาได้อย่างมีประสิทธิภาพ การใช้เทคโนโลยีที่เหมาะสมกับบริบทของโครงการ (เช่น pythainlp สำหรับภาษาไทย, Flask API สำหรับ Python-PHP Integration) ช่วยลดความซับซ้อนและเพิ่มประสิทธิภาพของระบบได้อย่างมีนัยสำคัญ

---

## 3.8 การประเมินผลและบทเรียนที่ได้รับจากการพัฒนา

### 3.8.1 จุดแข็งและความสำเร็จของโครงการ

1. การออกแบบสถาปัตยกรรมระบบ (System Architecture Design)

การนำหลักการ 3-Tier Architecture มาประยุกต์ใช้ในโครงการนี้ ถือเป็นการตัดสินใจที่ถูกต้องและเหมาะสม เนื่องจาก:

- Separation of Concerns: การแยก Presentation Layer, Application Layer และ Data Layer ออกจากกันอย่างชัดเจน ทำให้แต่ละส่วนสามารถพัฒนา ทดสอบ และดูแลรักษาได้อย่างอิสระ โดยไม่กระทบต่อส่วนอื่น ซึ่งสอดคล้องกับหลักการ Software Engineering สมัยใหม่

- RESTful API Design: การออกแบบ Backend เป็น REST API ทำให้ระบบมีความยืดหยุ่นสูง สามารถเชื่อมต่อกับ Frontend ได้หลากหลายรูปแบบ และสามารถขยายระบบในอนาคตได้ง่าย เช่น การพัฒนา Mobile Application หรือการเชื่อมต่อกับระบบอื่นๆ

- Hybrid Approach Strategy: การผสมผสานระหว่าง Rule-based System และ Machine Learning เป็นกลยุทธ์ที่ชาญฉลาด เนื่องจาก:
  - Rule-based System ทำงานได้รวดเร็วและแม่นยำสำหรับคำถามที่ตรงตัว
  - Machine Learning ช่วยจัดการคำถามที่มีความหลากหลายและไม่เคยพบมาก่อน
  - การใช้ Confidence Threshold (0.8) เป็นตัวกรองช่วยลด False Positive และเพิ่มความน่าเชื่อถือของระบบ

2. เทคโนโลยีที่เลือกใช้
- Python + pythainlp เหมาะกับการประมวลผลภาษาไทยมาก
- PHP + MySQL ติดตั้งง่าย ใช้งานง่าย เหมาะกับโปรเจกต์ขนาดกลาง
- TF-IDF + Logistic Regression ให้ผลลัพธ์ดีและเทรนเร็ว ไม่ต้องการ GPU
- Flask API ทำให้แยก Python environment ออกจาก PHP ได้สะดวก

3. การจัดการข้อมูล
- การนำเข้าข้อมูลบุคลากร 118 คน สำเร็จครบถ้วน
- การสร้าง Question Variations อัตโนมัติช่วยเพิ่ม training data ได้มาก
- การออกแบบ Database schema ดี ไม่มีปัญหาด้าน performance

4. User Experience
- UI สวยงาม ใช้งานง่าย Responsive ดี (คะแนน 4.4/5 จาก UAT)
- Response time เร็ว (average 267ms) ผู้ใช้พึงพอใจ
- Dark Mode และ Quick Action Cards ช่วยเพิ่ม UX

### 3.8.2 ปัญหาที่พบและแนวทางการแก้ไข

1. ข้อจำกัดของ Training Data
- ปัญหา: แม้จะมี 554 รายการ FAQ แต่บางหมวดหมู่ยังมีข้อมูลน้อย (เช่น research, regulations)
- วิธีแก้: 
  - สร้าง variations อัตโนมัติเพื่อเพิ่มปริมาณ training data
  - วางแผนเก็บ FAQ เพิ่มเติมอย่างต่อเนื่อง
  - ใช้ Rule-based fallback เมื่อ confidence ต่ำ

2. การบูรณาการ Python-PHP
- ปัญหา: PHP ไม่สามารถโหลด pickle models ได้โดยตรง
- วิธีแก้: 
  - สร้าง Flask API แยกต่างหาก
  - ใช้ HTTP Request เชื่อมต่อระหว่าง PHP กับ Python
  - เพิ่ม error handling สำหรับกรณี API ล้มเหลว

3. Performance กับ Concurrent Users
- ปัญหา: เมื่อ user มากกว่า 150 คน response time สูงขึ้นมาก
- วิธีแก้ปัจจุบัน: 
  - Rate Limiting (10 requests/min)
  - Connection pooling
- แผนปรับปรุง:
  - เพิ่ม Redis Cache สำหรับคำถามที่ถามบ่อย
  - Load Balancing ถ้ามี traffic สูง

4. ความเป็นธรรมชาติของคำตอบ
- ปัญหา: คำตอบบางข้อยาวเกินไป ไม่เป็นธรรมชาติ
- แผนปรับปรุง:
  - ปรับคำตอบให้สั้นกระชับขึ้น
  - เพิ่ม follow-up questions
  - สร้าง summary สำหรับคำตอบยาว

### 3.8.3 ข้อเสนอแนะสำหรับการพัฒนาในอนาคต

1. การวางแผนเก็บข้อมูล
- ควรเริ่มเก็บ FAQ ตั้งแต่ช่วงแรก ไม่ใช่ช่วงท้าย
- ควรมีทีมเฉพาะรับผิดชอบเก็บข้อมูลแต่ละหมวด
- ควรวางเป้าหมาย FAQ ที่สมจริงกว่า (100-150 แทน 250-400)

2. การทดสอบ
- ควรมี UAT ตั้งแต่ระยะกลางของโปรเจกต์
- ควรทดสอบ Load/Stress testing ก่อนหน้านี้
- ควรมี Automated Testing สำหรับ Regression

3. การใช้เทคโนโลยี
- พิจารณาใช้ Deep Learning (BERT, GPT) ถ้ามีทรัพยากร
- พิจารณาใช้ Vector Database สำหรับ Semantic Search
- พิจารณาใช้ Docker สำหรับ Deployment ที่ง่ายขึ้น

4. Documentation
- การจัดทำเอกสารควรทำไปพร้อมกับการพัฒนา ไม่ใช่หลังเสร็จ
- ควรมี Screenshot และ Diagram จริงๆ ตั้งแต่แรก
- ควรบันทึก Decision Log (ทำไมเลือกเทคนิคนี้)

### 3.8.4 คำแนะนำสำหรับผู้พัฒนาระบบ Chatbot ภาษาไทย

สำหรับโปรเจกต์ Chatbot ภาษาไทย:

1. ใช้ pythainlp เสมอ - ดีที่สุดสำหรับภาษาไทย
2. เริ่มจาก Simple Model ก่อน - TF-IDF + Logistic Regression ดีพอ ไม่ต้อง Deep Learning ทุกครั้ง
3. Hybrid Approach คือคำตอบ - ผสม Rule-based กับ ML จะได้ผลดีกว่า ML อย่างเดียว
4. FAQ คือหัวใจ - ระบบจะดีแค่ไหนขึ้นอยู่กับคุณภาพและปริมาณของ FAQ
5. Testing กับ Real Users - UAT สำคัญมาก ได้ feedback ที่มีค่า

เทคนิค:
- ใช้ Question Variations เพื่อเพิ่ม training data
- ใช้ Confidence Threshold (0.8) เพื่อกรอง prediction ที่ไม่แน่ใจ
- บันทึก Chat Logs เพื่อวิเคราะห์และปรับปรุงระบบ
- ให้ผู้ใช้ Feedback เพื่อปรับปรุงต่อเนื่อง

ข้อควรระวัง:
- ภาษาไทยมีความซับซ้อน ต้องทดสอบให้ดี
- Training data ต้องมีคุณภาพ ไม่ใช่แค่ปริมาณ
- Performance testing สำคัญ โดยเฉพาะ concurrent users
- Security ต้องคิดตั้งแต่แรก ไม่ใช่ปิดท้าย

### 3.8.5 การพัฒนาทักษะและความรู้ที่ได้รับ

ทักษะทางเทคนิค:
- NLP สำหรับภาษาไทย (pythainlp, text preprocessing)
- Machine Learning (TF-IDF, Logistic Regression, scikit-learn)
- Full-stack Development (PHP, JavaScript, MySQL, Python)
- REST API Design และ Integration
- Database Design และ Optimization

ทักษะอื่นๆ:
- การวางแผนโปรเจกต์และบริหารเวลา
- การทำงานเป็นทีม
- การเก็บรวบรวมและจัดการข้อมูล
- การทดสอบและ Quality Assurance
- การเขียน Documentation


